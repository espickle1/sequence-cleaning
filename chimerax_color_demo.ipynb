{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/espickle1/sequence-cleaning/blob/main/chimerax_color_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueXiD7-9aeQl"
      },
      "source": [
        "# ChimeraX Color Script Generator\n",
        "\n",
        "Upload per-residue entropy (or any scalar) values, sequences, and metadata.\n",
        "This notebook generates a `.cxc` ChimeraX color script **per sequence** and\n",
        "downloads them to your machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCVVA1A6aeQm"
      },
      "source": [
        "## 0. Setup – Clone repo & install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky2AL_smaeQm",
        "outputId": "610914d4-1c9e-433b-ec5e-e5f74e978edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory: /content/sequence-cleaning\n"
          ]
        }
      ],
      "source": [
        "import os, subprocess\n",
        "\n",
        "repo_dir = \"sequence-cleaning\"\n",
        "if not os.path.isdir(repo_dir):\n",
        "    subprocess.run(\n",
        "        [\"git\", \"clone\", \"https://github.com/espickle1/sequence-cleaning.git\"],\n",
        "        check=True,\n",
        "    )\n",
        "\n",
        "if os.path.basename(os.getcwd()) != repo_dir:\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IshNBpejaeQn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from analysis.chimerax_color_lib import (\n",
        "    generate_chimerax_script,\n",
        "    generate_chimerax_script_with_scalers,\n",
        "    write_chimerax_script,\n",
        "    fit_scaler,\n",
        "    fit_minmax_scaler,\n",
        "    scale_values_with_scaler,\n",
        "    scale_values,\n",
        "    compute_value_statistics,\n",
        "    parse_range_string,\n",
        "    create_value_mask,\n",
        "    display_statistics_summary,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv0sRFnZaeQn"
      },
      "source": [
        "## 1. Upload files\n",
        "\n",
        "Upload three CSV files:\n",
        "- **Metadata file** – must contain `sequence_id` and `name` columns.\n",
        "- **Sequences file** – must contain `sequence_id` and `sequence` columns.\n",
        "- **Entropy file** – per-residue entropy values. Expected columns: `sequence_id` plus one or more value columns, **or** a single per-residue file (e.g. `residue_position, entropy, ...`) that applies to one sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "OP6vrFPuaeQn",
        "outputId": "79666a43-180c-4d4d-fdd4-57e26900398e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload the METADATA file (.csv):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f26d5b9-238d-495f-b817-0409228fb7b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f26d5b9-238d-495f-b817-0409228fb7b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving metadata.csv to metadata (1).csv\n",
            "Loaded metadata (1).csv: (12, 10)\n",
            "Columns: ['sequence_id', 'original_header', 'name', 'date', 'source_file', 'field_1', 'field_2', 'field_3', 'field_4', 'field_5']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     sequence_id                                    original_header    name  \\\n",
              "0   0ea58344488f  PB1|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...     PB1   \n",
              "1   3bfaf386b5b9  PB1-F2|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024...  PB1-F2   \n",
              "2   301aaa17b0da  NS1|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...     NS1   \n",
              "3   7c2779a1aec1  NEP|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...     NEP   \n",
              "4   2e51a71e2288  PB2|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...     PB2   \n",
              "5   a9003eeee5e9  M1|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...      M1   \n",
              "6   7b65cc89178f  M2|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...      M2   \n",
              "7   41343588f288  NA|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...     NaN   \n",
              "8   2d720887d514  PA|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...      PA   \n",
              "9   2a0b35718118  HA|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...      HA   \n",
              "10  0a57da14d26a  NP|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...      NP   \n",
              "11  a547edc36a13  PA-X|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-0...    PA-X   \n",
              "\n",
              "          date                       source_file   field_1          field_2  \\\n",
              "0   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "1   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "2   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "3   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "4   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "5   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "6   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "7   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "8   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "9   2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "10  2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "11  2024-03-28  gisaid_epiflu_sequence (3).fasta  A / H5N1  A/Texas/37/2024   \n",
              "\n",
              "     field_3           field_4     field_5  \n",
              "0   2.3.4.4b  EPI_ISL_19027114  EPI3171490  \n",
              "1   2.3.4.4b  EPI_ISL_19027114  EPI3171490  \n",
              "2   2.3.4.4b  EPI_ISL_19027114  EPI3171491  \n",
              "3   2.3.4.4b  EPI_ISL_19027114  EPI3171491  \n",
              "4   2.3.4.4b  EPI_ISL_19027114  EPI3171492  \n",
              "5   2.3.4.4b  EPI_ISL_19027114  EPI3171493  \n",
              "6   2.3.4.4b  EPI_ISL_19027114  EPI3171493  \n",
              "7   2.3.4.4b  EPI_ISL_19027114  EPI3171486  \n",
              "8   2.3.4.4b  EPI_ISL_19027114  EPI3171487  \n",
              "9   2.3.4.4b  EPI_ISL_19027114  EPI3171488  \n",
              "10  2.3.4.4b  EPI_ISL_19027114  EPI3171489  \n",
              "11  2.3.4.4b  EPI_ISL_19027114  EPI3171487  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a200193-317a-48e2-afa6-0e221b1c6dc5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>original_header</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>source_file</th>\n",
              "      <th>field_1</th>\n",
              "      <th>field_2</th>\n",
              "      <th>field_3</th>\n",
              "      <th>field_4</th>\n",
              "      <th>field_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0ea58344488f</td>\n",
              "      <td>PB1|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...</td>\n",
              "      <td>PB1</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3bfaf386b5b9</td>\n",
              "      <td>PB1-F2|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024...</td>\n",
              "      <td>PB1-F2</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>301aaa17b0da</td>\n",
              "      <td>NS1|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...</td>\n",
              "      <td>NS1</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7c2779a1aec1</td>\n",
              "      <td>NEP|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...</td>\n",
              "      <td>NEP</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2e51a71e2288</td>\n",
              "      <td>PB2|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03...</td>\n",
              "      <td>PB2</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a9003eeee5e9</td>\n",
              "      <td>M1|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...</td>\n",
              "      <td>M1</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7b65cc89178f</td>\n",
              "      <td>M2|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...</td>\n",
              "      <td>M2</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>41343588f288</td>\n",
              "      <td>NA|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2d720887d514</td>\n",
              "      <td>PA|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...</td>\n",
              "      <td>PA</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2a0b35718118</td>\n",
              "      <td>HA|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...</td>\n",
              "      <td>HA</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0a57da14d26a</td>\n",
              "      <td>NP|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-...</td>\n",
              "      <td>NP</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>a547edc36a13</td>\n",
              "      <td>PA-X|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-0...</td>\n",
              "      <td>PA-X</td>\n",
              "      <td>2024-03-28</td>\n",
              "      <td>gisaid_epiflu_sequence (3).fasta</td>\n",
              "      <td>A / H5N1</td>\n",
              "      <td>A/Texas/37/2024</td>\n",
              "      <td>2.3.4.4b</td>\n",
              "      <td>EPI_ISL_19027114</td>\n",
              "      <td>EPI3171487</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a200193-317a-48e2-afa6-0e221b1c6dc5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a200193-317a-48e2-afa6-0e221b1c6dc5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a200193-317a-48e2-afa6-0e221b1c6dc5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f42a46f2-6e1c-4b1a-84a8-872f9613e3aa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_metadata')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f42a46f2-6e1c-4b1a-84a8-872f9613e3aa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_metadata');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_metadata",
              "summary": "{\n  \"name\": \"df_metadata\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"sequence_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"0a57da14d26a\",\n          \"2a0b35718118\",\n          \"0ea58344488f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_header\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"NP|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-28|EPI_ISL_19027114|EPI3171489\",\n          \"HA|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-28|EPI_ISL_19027114|EPI3171488\",\n          \"PB1|A / H5N1|A/Texas/37/2024||2.3.4.4b|2024-03-28|EPI_ISL_19027114|EPI3171490\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"M1\",\n          \"PB1\",\n          \"NP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2024-03-28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_file\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gisaid_epiflu_sequence (3).fasta\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A / H5N1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"A/Texas/37/2024\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2.3.4.4b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"EPI_ISL_19027114\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"EPI3171491\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Upload the METADATA file (.csv):\")\n",
        "meta_upload = files.upload()\n",
        "meta_filename = list(meta_upload.keys())[0]\n",
        "df_metadata = pd.read_csv(meta_filename)\n",
        "print(f\"Loaded {meta_filename}: {df_metadata.shape}\")\n",
        "print(f\"Columns: {list(df_metadata.columns)}\")\n",
        "display(df_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "4oZ7WpXmcYs6",
        "outputId": "1e13858c-b839-4213-a584-2ae45d505bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload the SEQUENCES file (.csv):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c7ea0a4-439c-4288-92eb-7d23ec3d6a58\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c7ea0a4-439c-4288-92eb-7d23ec3d6a58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sequences.csv to sequences (1).csv\n",
            "Loaded sequences (1).csv: (12, 3)\n",
            "Columns: ['sequence_id', 'sequence', 'length']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     sequence_id                                           sequence  length\n",
              "0   0ea58344488f  MDVNPTLLFLKVPAQNAISTTFPYTGDPPYSHGTGTGYTMDTVNRT...     757\n",
              "1   3bfaf386b5b9  MEQEQDIPWTQLTEHINIQKKGNGQQTQKPGHLNSIQLMDHCLMTM...      90\n",
              "2   301aaa17b0da  MDSNTVLSFQVDCFLWHVRKRFADQELGDAPFLDRLRRDRKSLRGR...     230\n",
              "3   7c2779a1aec1  MDSNTVLSFQDILMRMSKMQLGSSSEDLNGMITQFESLKLYRDSLG...     121\n",
              "4   2e51a71e2288  MERIKELRDLMSQSRTREILTKTTVDHMAIIKKYTSGRQEKNPALR...     759\n",
              "5   a9003eeee5e9  MSLLTEVETYVLSIVPSGPLKAEIAQRLEDVFAGKNTDLEALMEWL...     252\n",
              "6   7b65cc89178f  MSLLTEVETPTKNGWECNCSDSSDPLVIAASIIGILHLILWILDRL...      97\n",
              "7   41343588f288  MNPNQKITTIGSICMVIGIVSLMLQIGNIISIWVSHSIQTGNQYQP...     469\n",
              "8   2d720887d514  MEDFVRQCFNPMIVELAEKAMKEYGEDPKIETNKFAAICTHLEVCF...     716\n",
              "9   2a0b35718118  MENIVLLLAIVSLVKSDQICIGYHANNSTEQVDTIMEKNVTVTHAQ...     567\n",
              "10  0a57da14d26a  MASQGTKRSYEQMETGGERQNATEIRASVGRMVGGIGRFYIQMCTE...     498\n",
              "11  a547edc36a13  MEDFVRQCFNPMIVELAEKAMKEYGEDPKIETNKFAAICTHLEVCF...     252"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e932c366-a067-4a43-b803-c8b2c8db1040\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>sequence</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0ea58344488f</td>\n",
              "      <td>MDVNPTLLFLKVPAQNAISTTFPYTGDPPYSHGTGTGYTMDTVNRT...</td>\n",
              "      <td>757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3bfaf386b5b9</td>\n",
              "      <td>MEQEQDIPWTQLTEHINIQKKGNGQQTQKPGHLNSIQLMDHCLMTM...</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>301aaa17b0da</td>\n",
              "      <td>MDSNTVLSFQVDCFLWHVRKRFADQELGDAPFLDRLRRDRKSLRGR...</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7c2779a1aec1</td>\n",
              "      <td>MDSNTVLSFQDILMRMSKMQLGSSSEDLNGMITQFESLKLYRDSLG...</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2e51a71e2288</td>\n",
              "      <td>MERIKELRDLMSQSRTREILTKTTVDHMAIIKKYTSGRQEKNPALR...</td>\n",
              "      <td>759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a9003eeee5e9</td>\n",
              "      <td>MSLLTEVETYVLSIVPSGPLKAEIAQRLEDVFAGKNTDLEALMEWL...</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7b65cc89178f</td>\n",
              "      <td>MSLLTEVETPTKNGWECNCSDSSDPLVIAASIIGILHLILWILDRL...</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>41343588f288</td>\n",
              "      <td>MNPNQKITTIGSICMVIGIVSLMLQIGNIISIWVSHSIQTGNQYQP...</td>\n",
              "      <td>469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2d720887d514</td>\n",
              "      <td>MEDFVRQCFNPMIVELAEKAMKEYGEDPKIETNKFAAICTHLEVCF...</td>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2a0b35718118</td>\n",
              "      <td>MENIVLLLAIVSLVKSDQICIGYHANNSTEQVDTIMEKNVTVTHAQ...</td>\n",
              "      <td>567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0a57da14d26a</td>\n",
              "      <td>MASQGTKRSYEQMETGGERQNATEIRASVGRMVGGIGRFYIQMCTE...</td>\n",
              "      <td>498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>a547edc36a13</td>\n",
              "      <td>MEDFVRQCFNPMIVELAEKAMKEYGEDPKIETNKFAAICTHLEVCF...</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e932c366-a067-4a43-b803-c8b2c8db1040')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e932c366-a067-4a43-b803-c8b2c8db1040 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e932c366-a067-4a43-b803-c8b2c8db1040');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_3634d36e-0e60-4fdf-9ab6-3090cbc6dd83\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sequences')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3634d36e-0e60-4fdf-9ab6-3090cbc6dd83 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sequences');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sequences",
              "summary": "{\n  \"name\": \"df_sequences\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"sequence_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"0a57da14d26a\",\n          \"2a0b35718118\",\n          \"0ea58344488f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"MASQGTKRSYEQMETGGERQNATEIRASVGRMVGGIGRFYIQMCTELKLSDHEGRLIQNSITIERMVLSAFDERRNKYLEEHPSAGKDPKKTGGPIYRRRDGKWMRELILYDKEEIRRIWRQANNGEDATAGLTHLMIWHSNLNDATYQRTRALVRTGMDPRMCSLMQGSTLPRRSGAAGAAVKGVGTMVMELIRMIKRGINDRNFWRGENGRRTRIAYERMCNILKGKFQTAAQRAMMDQVRESRNPGNAEIEDLIFLARSALILRGSVAHKSCLPACVYGLAVASGYDFEREGYSLVGIDPFRLLQNSQVFSLIRPNENPAHKSQLVWMACHSAAFEDLRVSSFIRGTRVVPRGQLSTRGVQIASNENMETMDSSTLELRSRYWAIRTRSGGNTNQQRASAGQISVQPTFSVQRNLPFERATIMAAFTGNTEGRTSDMRTEIIRMMENARPEDVSFQGRGVFELSDEKATNPIVPSFDMNNEGSYFFGDNAEEYDN\",\n          \"MENIVLLLAIVSLVKSDQICIGYHANNSTEQVDTIMEKNVTVTHAQDILEKTHNGKLCDLNGVKPLILKDCSVAGWLLGNPMCDEFIRVPEWSYIVERANPANDLCYPGSLNDYEELKHMLSRINHFEKIQIIPKSSWPNHETSLGVSAACPYQGAPSFFRNVVWLIKKNDAYPTIKISYNNTNREDLLILWGIHHSNNAEEQTNLYKNPITYISVGTSTLNQRLAPKIATRSQVNGQRGRMDFFWTILKPDDAIHFESNGNFIAPEYAYKIVKKGDSTIMKSGVEYGHCNTKCQTPVGAINSSMPFHNIHPLTIGECPKYVKSNKLVLATGLRNSPLREKRRKRGLFGA_AGFIEGGWQGMVDGWYGYHHSNEQGSGYAADKESTQKAIDGVTNKVNSIIDKMNTQFEAVGREFNNLERRIENLNKKMEDGFLDVWTYNAELLVLMENERTLDFHDSNVKNLYDKVRLQLRDNAKELGNGCFEFYHKCDNECMESVRNGTYDYPQYSEEARLKREEISGVKLESVGTYQILSIYSTAASSLALAIMMAGLSLWMCSNGSLQCRICI\",\n          \"MDVNPTLLFLKVPAQNAISTTFPYTGDPPYSHGTGTGYTMDTVNRTHQYSEKGKWTTNSETGAPQLNPIDGPLPDDNEPSGYAQTDCVLEAMAFLEESHPGIFENSCLETMEVVQQTRVDKLTQGRQTYDWTLNRNQPAATALANTIEVFRSNGLTANESGRLIDFLKDVVESMDKEEIEITTHFQRKRRVRDNMTKKMVTQRTIGKKKQRLNKRSYLIRALTLNTMTKDAERGKLKRRAIATPGMQIRGFVYFVETLARSICEKLEQSGLPVGGNEKKAKLANVVRKMMTNSQDTELSFTITGDNTKWNENQNPRMFLAMITYITRNQPEWFRNVLSIAPIMFSNKMARLGKGYMFESKSMKLRTQIPAEMLASIDLKYFNESTRKKIEKVRPLLIDGTASLSPGMMMGMFNMLSTVLGVSILNLGQKKYTKTTYWWDGLQSSDDFALIVNAPNHEGIQAGVDRFYRTCKLVGINMSKKKSYINRTGTFEFTSFFYRYGFVANFSMELPSFGVSGINESADMSIGVTVIKNNMINNDLGPATAQMALQLFIKDYRYTYRCHRGDTQIQTRRSFELKKLWEQTRSKPGLLVSDGGPNLYNIRNLHIPEVCLKWELMDEDYQGRLCNPLNPFVSHKEIESVNNAVVMPAHGPAKSMEYDAVATTHSWIPKRNRSILNTSQRGILEDEQMYQKCCNLFEKFFPSSSYRRPVGISSMVEAMVSRARIDARIDFESGRIKKEEFAEIMKICSTIEELRRQK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 258,\n        \"min\": 90,\n        \"max\": 759,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          252,\n          757,\n          567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Upload the SEQUENCES file (.csv):\")\n",
        "seq_upload = files.upload()\n",
        "seq_filename = list(seq_upload.keys())[0]\n",
        "df_sequences = pd.read_csv(seq_filename)\n",
        "print(f\"Loaded {seq_filename}: {df_sequences.shape}\")\n",
        "print(f\"Columns: {list(df_sequences.columns)}\")\n",
        "display(df_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "4EEsVuadcWIB",
        "outputId": "008f2df6-df1f-4844-b88f-9ea3d3e5766b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload the ENTROPY file (.csv):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c225d53-dc20-4708-9ae0-88882a3b125e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0c225d53-dc20-4708-9ae0-88882a3b125e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving entropy_per_residue_2e51a71e2288.csv to entropy_per_residue_2e51a71e2288.csv\n",
            "Loaded entropy_per_residue_2e51a71e2288.csv: (761, 3)\n",
            "Columns: ['residue_position', 'entropy', 'classification']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   residue_position   entropy classification\n",
              "0                 1  2.437500    constrained\n",
              "1                 2  0.500000    constrained\n",
              "2                 3  2.640625   intermediate\n",
              "3                 4  2.765625   intermediate\n",
              "4                 5  2.750000   intermediate"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef08f70b-d14d-44a7-84ce-0fab132f412b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>residue_position</th>\n",
              "      <th>entropy</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.437500</td>\n",
              "      <td>constrained</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>constrained</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2.640625</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2.765625</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2.750000</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef08f70b-d14d-44a7-84ce-0fab132f412b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef08f70b-d14d-44a7-84ce-0fab132f412b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef08f70b-d14d-44a7-84ce-0fab132f412b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_entropy",
              "summary": "{\n  \"name\": \"df_entropy\",\n  \"rows\": 761,\n  \"fields\": [\n    {\n      \"column\": \"residue_position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 219,\n        \"min\": 1,\n        \"max\": 761,\n        \"num_unique_values\": 761,\n        \"samples\": [\n          397,\n          325,\n          98\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19952952902182963,\n        \"min\": 0.5,\n        \"max\": 2.921875,\n        \"num_unique_values\": 56,\n        \"samples\": [\n          2.4375,\n          2.78125,\n          2.65625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classification\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"constrained\",\n          \"intermediate\",\n          \"flexible\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "print(\"Upload the ENTROPY file (.csv):\")\n",
        "entropy_upload = files.upload()\n",
        "entropy_filename = list(entropy_upload.keys())[0]\n",
        "df_entropy = pd.read_csv(entropy_filename)\n",
        "print(f\"Loaded {entropy_filename}: {df_entropy.shape}\")\n",
        "print(f\"Columns: {list(df_entropy.columns)}\")\n",
        "df_entropy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaaQE8lqJV-e"
      },
      "source": [
        "## 1b. Multi-file normalization (optional)\n",
        "\n",
        "Enable this to normalize entropy values across **multiple** entropy files. This ensures\n",
        "all sequences use the same color scale, making comparisons meaningful.\n",
        "\n",
        "- **Single file mode** (default): Each sequence is colored based on its own min/max values.\n",
        "- **Multi-file mode**: All entropy values are combined to compute a shared scale, then each\n",
        "  sequence is colored using that shared scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c8SN0vxFJV-f",
        "outputId": "275863f9-921a-42eb-9ed0-88f17e5a0be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use multi-file normalization? (y/n) [n]: y\n",
            "\n",
            "--- Multi-file mode enabled ---\n",
            "Upload additional entropy files. These will be combined with the first file\n",
            "to compute a shared normalization scale.\n",
            "You will specify model/chain IDs for each file.\n",
            "\n",
            "File 1: entropy_per_residue_2e51a71e2288.csv -> PB2\n",
            "  Model ID for 'PB2' [1]: 1\n",
            "  Chain ID for 'PB2' (blank for none): b\n",
            "  -> Model #1/b, 761 residues\n",
            "\n",
            "Upload another entropy file? (y/n) [n]: y\n",
            "\n",
            "Upload the next ENTROPY file (.csv):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b54663c8-a1f6-46b4-a824-fc270eee2e77\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b54663c8-a1f6-46b4-a824-fc270eee2e77\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving entropy_per_residue_2d720887d514.csv to entropy_per_residue_2d720887d514.csv\n",
            "File 2: entropy_per_residue_2d720887d514.csv -> PA\n",
            "  Model ID for 'PA' [2]: 1\n",
            "  Chain ID for 'PA' (blank for none): c\n",
            "  -> Model #1/c, 718 residues\n",
            "\n",
            "Upload another entropy file? (y/n) [n]: y\n",
            "\n",
            "Upload the next ENTROPY file (.csv):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ce268c4-3a00-46ae-b371-e58c5c447e95\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ce268c4-3a00-46ae-b371-e58c5c447e95\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving entropy_per_residue_0ea58344488f.csv to entropy_per_residue_0ea58344488f.csv\n",
            "File 3: entropy_per_residue_0ea58344488f.csv -> PB1\n",
            "  Model ID for 'PB1' [3]: 1\n",
            "  Chain ID for 'PB1' (blank for none): a\n",
            "  -> Model #1/a, 759 residues\n",
            "\n",
            "Upload another entropy file? (y/n) [n]: n\n",
            "\n",
            "=== Loaded 3 entropy file(s) for multi-file normalization ===\n",
            "  1. PB2 (2e51a71e2288): 761 residues, #1/b\n",
            "  2. PA (2d720887d514): 718 residues, #1/c\n",
            "  3. PB1 (0ea58344488f): 759 residues, #1/a\n"
          ]
        }
      ],
      "source": [
        "# --- Multi-file normalization setup ---\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "_multi = input(\"Use multi-file normalization? (y/n) [n]: \").strip().lower()\n",
        "MULTI_FILE_MODE = _multi in (\"y\", \"yes\")\n",
        "\n",
        "# Store all entropy data: list of dicts with 'seq_id', 'label', 'values', 'filename', 'model', 'chain'\n",
        "all_entropy_data = []\n",
        "\n",
        "if MULTI_FILE_MODE:\n",
        "    print(\"\\n--- Multi-file mode enabled ---\")\n",
        "    print(\"Upload additional entropy files. These will be combined with the first file\")\n",
        "    print(\"to compute a shared normalization scale.\")\n",
        "    print(\"You will specify model/chain IDs for each file.\\n\")\n",
        "\n",
        "    # Add the first file that was already uploaded\n",
        "    if \"sequence_id\" not in df_entropy.columns:\n",
        "        # Per-residue format - extract seq_id from filename\n",
        "        match = re.search(r\"entropy_per_residue_(.+)\\.csv\", entropy_filename)\n",
        "        first_seq_id = match.group(1) if match else Path(entropy_filename).stem\n",
        "\n",
        "        # Get value column\n",
        "        if \"entropy\" in df_entropy.columns:\n",
        "            value_col = \"entropy\"\n",
        "        else:\n",
        "            numeric_cols = [c for c in df_entropy.select_dtypes(include=\"number\").columns if c != \"residue_position\"]\n",
        "            value_col = numeric_cols[0] if numeric_cols else df_entropy.columns[-1]\n",
        "\n",
        "        # Look up name from metadata\n",
        "        first_label = first_seq_id\n",
        "        if \"name\" in df_metadata.columns and \"sequence_id\" in df_metadata.columns:\n",
        "            name_match = df_metadata.loc[df_metadata[\"sequence_id\"] == first_seq_id, \"name\"]\n",
        "            if len(name_match) and pd.notna(name_match.iloc[0]):\n",
        "                first_label = name_match.iloc[0]\n",
        "\n",
        "        # Get model/chain for first file\n",
        "        print(f\"File 1: {entropy_filename} -> {first_label}\")\n",
        "        _model = input(f\"  Model ID for '{first_label}' [1]: \").strip() or \"1\"\n",
        "        _chain = input(f\"  Chain ID for '{first_label}' (blank for none): \").strip()\n",
        "\n",
        "        all_entropy_data.append({\n",
        "            \"seq_id\": first_seq_id,\n",
        "            \"label\": first_label,\n",
        "            \"values\": df_entropy[value_col].values.astype(float),\n",
        "            \"filename\": entropy_filename,\n",
        "            \"model\": int(_model),\n",
        "            \"chain\": _chain,\n",
        "        })\n",
        "        print(f\"  -> Model #{_model}\" + (f\"/{_chain}\" if _chain else \"\") + f\", {len(df_entropy)} residues\\n\")\n",
        "    else:\n",
        "        raise ValueError(\"Multi-file mode currently only supports per-residue format (Format B) entropy files.\")\n",
        "\n",
        "    # Upload additional files\n",
        "    while True:\n",
        "        _more = input(\"Upload another entropy file? (y/n) [n]: \").strip().lower()\n",
        "        if _more not in (\"y\", \"yes\"):\n",
        "            break\n",
        "\n",
        "        print(\"\\nUpload the next ENTROPY file (.csv):\")\n",
        "        extra_upload = files.upload()\n",
        "        extra_filename = list(extra_upload.keys())[0]\n",
        "        df_extra = pd.read_csv(extra_filename)\n",
        "\n",
        "        if \"sequence_id\" in df_extra.columns:\n",
        "            print(\"Warning: File has sequence_id column. Multi-file mode expects per-residue files.\")\n",
        "            continue\n",
        "\n",
        "        # Extract seq_id from filename\n",
        "        match = re.search(r\"entropy_per_residue_(.+)\\.csv\", extra_filename)\n",
        "        extra_seq_id = match.group(1) if match else Path(extra_filename).stem\n",
        "\n",
        "        # Get value column\n",
        "        if \"entropy\" in df_extra.columns:\n",
        "            extra_value_col = \"entropy\"\n",
        "        else:\n",
        "            numeric_cols = [c for c in df_extra.select_dtypes(include=\"number\").columns if c != \"residue_position\"]\n",
        "            extra_value_col = numeric_cols[0] if numeric_cols else df_extra.columns[-1]\n",
        "\n",
        "        # Look up name\n",
        "        extra_label = extra_seq_id\n",
        "        if \"name\" in df_metadata.columns and \"sequence_id\" in df_metadata.columns:\n",
        "            name_match = df_metadata.loc[df_metadata[\"sequence_id\"] == extra_seq_id, \"name\"]\n",
        "            if len(name_match) and pd.notna(name_match.iloc[0]):\n",
        "                extra_label = name_match.iloc[0]\n",
        "\n",
        "        # Get model/chain for this file\n",
        "        file_num = len(all_entropy_data) + 1\n",
        "        print(f\"File {file_num}: {extra_filename} -> {extra_label}\")\n",
        "        _model = input(f\"  Model ID for '{extra_label}' [{file_num}]: \").strip() or str(file_num)\n",
        "        _chain = input(f\"  Chain ID for '{extra_label}' (blank for none): \").strip()\n",
        "\n",
        "        all_entropy_data.append({\n",
        "            \"seq_id\": extra_seq_id,\n",
        "            \"label\": extra_label,\n",
        "            \"values\": df_extra[extra_value_col].values.astype(float),\n",
        "            \"filename\": extra_filename,\n",
        "            \"model\": int(_model),\n",
        "            \"chain\": _chain,\n",
        "        })\n",
        "        print(f\"  -> Model #{_model}\" + (f\"/{_chain}\" if _chain else \"\") + f\", {len(df_extra)} residues\\n\")\n",
        "\n",
        "    print(f\"\\n=== Loaded {len(all_entropy_data)} entropy file(s) for multi-file normalization ===\")\n",
        "    for i, data in enumerate(all_entropy_data, 1):\n",
        "        spec = f\"#{data['model']}\" + (f\"/{data['chain']}\" if data['chain'] else \"\")\n",
        "        print(f\"  {i}. {data['label']} ({data['seq_id']}): {len(data['values'])} residues, {spec}\")\n",
        "else:\n",
        "    print(\"Single-file mode: each sequence normalized independently.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO9cxKemaeQn"
      },
      "source": [
        "## 2. Merge files on `sequence_id`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "iWiT1xcnaeQn",
        "outputId": "66cc80b9-7108-48d6-ae40-3e8056941bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Format B detected (per-residue). Inferred sequence_id: 2e51a71e2288\n",
            "Use this sequence_id? (press Enter to accept, or type a new one): \n",
            "Using value column: 'entropy'\n",
            "Residues: 761\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   residue_position   entropy classification\n",
              "0                 1  2.437500    constrained\n",
              "1                 2  0.500000    constrained\n",
              "2                 3  2.640625   intermediate\n",
              "3                 4  2.765625   intermediate\n",
              "4                 5  2.750000   intermediate"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7def6ad-cf09-48fc-9b7b-7eadae8cd8a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>residue_position</th>\n",
              "      <th>entropy</th>\n",
              "      <th>classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.437500</td>\n",
              "      <td>constrained</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>constrained</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2.640625</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2.765625</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2.750000</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7def6ad-cf09-48fc-9b7b-7eadae8cd8a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7def6ad-cf09-48fc-9b7b-7eadae8cd8a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7def6ad-cf09-48fc-9b7b-7eadae8cd8a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(df_entropy\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"residue_position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.969694599957894,\n        \"min\": 0.5,\n        \"max\": 2.765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5,\n          2.75,\n          2.640625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classification\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"intermediate\",\n          \"constrained\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Detect entropy file format and build a unified structure\n",
        "#\n",
        "# Format A: Wide table with sequence_id + value columns (one row per sequence)\n",
        "# Format B: Per-residue table (residue_position, entropy, ...) for a single sequence\n",
        "#           In this case sequence_id is extracted from the filename.\n",
        "\n",
        "if \"sequence_id\" in df_entropy.columns:\n",
        "    # Format A -- entropy file already has sequence_id\n",
        "    available_ids = df_entropy[\"sequence_id\"].unique().tolist()\n",
        "    print(f\"Available sequence_ids ({len(available_ids)}):\")\n",
        "    for sid in available_ids:\n",
        "        print(f\"  - {sid}\")\n",
        "\n",
        "    print(\"\\nEnter sequence_id(s) to process (comma-separated), or 'all' for all:\")\n",
        "    selection = input(\"sequence_id(s) [all]: \").strip() or \"all\"\n",
        "\n",
        "    if selection.lower() == \"all\":\n",
        "        selected_ids = available_ids\n",
        "    else:\n",
        "        selected_ids = [s.strip() for s in selection.split(\",\") if s.strip()]\n",
        "        # Validate selections\n",
        "        invalid = [s for s in selected_ids if s not in available_ids]\n",
        "        if invalid:\n",
        "            print(f\"Warning: unknown sequence_id(s) ignored: {invalid}\")\n",
        "        selected_ids = [s for s in selected_ids if s in available_ids]\n",
        "\n",
        "    if not selected_ids:\n",
        "        raise ValueError(\"No valid sequence_id selected.\")\n",
        "\n",
        "    print(f\"\\nSelected {len(selected_ids)} sequence(s): {selected_ids}\")\n",
        "\n",
        "    # Filter entropy data to selected IDs\n",
        "    df_entropy_filtered = df_entropy[df_entropy[\"sequence_id\"].isin(selected_ids)]\n",
        "\n",
        "    merge_cols = [\"sequence_id\", \"sequence\"]\n",
        "    if \"sequence\" in df_sequences.columns:\n",
        "        df_merged = df_entropy_filtered.merge(\n",
        "            df_sequences[merge_cols], on=\"sequence_id\", how=\"inner\"\n",
        "        )\n",
        "    else:\n",
        "        df_merged = df_entropy_filtered.copy()\n",
        "\n",
        "    if \"name\" in df_metadata.columns:\n",
        "        df_merged = df_merged.merge(\n",
        "            df_metadata[[\"sequence_id\", \"name\"]], on=\"sequence_id\", how=\"left\"\n",
        "        )\n",
        "\n",
        "    value_columns = [\n",
        "        c for c in df_entropy.columns if c != \"sequence_id\"\n",
        "    ]\n",
        "    print(f\"Format A detected (wide table). Value columns: {value_columns}\")\n",
        "    print(f\"Merged rows: {len(df_merged)}\")\n",
        "    display(df_merged.head())\n",
        "    ENTROPY_FORMAT = \"wide\"\n",
        "\n",
        "else:\n",
        "    # Format B -- per-residue file without sequence_id\n",
        "    # Try to extract sequence_id from the entropy filename\n",
        "    # Pipeline exports files named like: entropy_per_residue_{seq_id}.csv\n",
        "    import re\n",
        "    match = re.search(r\"entropy_per_residue_(.+)\\.csv\", entropy_filename)\n",
        "    if match:\n",
        "        inferred_seq_id = match.group(1)\n",
        "    else:\n",
        "        inferred_seq_id = Path(entropy_filename).stem\n",
        "\n",
        "    print(f\"Format B detected (per-residue). Inferred sequence_id: {inferred_seq_id}\")\n",
        "    override = input(f\"Use this sequence_id? (press Enter to accept, or type a new one): \").strip()\n",
        "    if override:\n",
        "        inferred_seq_id = override\n",
        "        print(f\"Using sequence_id: {inferred_seq_id}\")\n",
        "\n",
        "    # Determine which column holds the values\n",
        "    if \"entropy\" in df_entropy.columns:\n",
        "        value_col = \"entropy\"\n",
        "    else:\n",
        "        # Use the first numeric column that isn't residue_position\n",
        "        numeric_cols = [\n",
        "            c for c in df_entropy.select_dtypes(include=\"number\").columns\n",
        "            if c != \"residue_position\"\n",
        "        ]\n",
        "        value_col = numeric_cols[0] if numeric_cols else df_entropy.columns[-1]\n",
        "\n",
        "    print(f\"Using value column: '{value_col}'\")\n",
        "    print(f\"Residues: {len(df_entropy)}\")\n",
        "\n",
        "    # Look up the name from metadata\n",
        "    label = inferred_seq_id\n",
        "    if \"name\" in df_metadata.columns and \"sequence_id\" in df_metadata.columns:\n",
        "        name_match = df_metadata.loc[\n",
        "            df_metadata[\"sequence_id\"] == inferred_seq_id, \"name\"\n",
        "        ]\n",
        "        if len(name_match):\n",
        "            label = name_match.iloc[0]\n",
        "\n",
        "    # Store for the generation step\n",
        "    df_merged = None\n",
        "    per_residue_info = {\n",
        "        \"seq_id\": inferred_seq_id,\n",
        "        \"label\": label,\n",
        "        \"values\": df_entropy[value_col].values.astype(float),\n",
        "    }\n",
        "    value_columns = None\n",
        "    ENTROPY_FORMAT = \"per_residue\"\n",
        "    display(df_entropy.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LXqXapPaeQo"
      },
      "source": [
        "## 3. Configure color mapping\n",
        "\n",
        "Adjust these parameters as needed before generating the scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhRoMu5RaeQo",
        "outputId": "edeabbd2-8060-4f82-9637-2acacf81f596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colormap name [Greys]: RdBu\n",
            "Transform methods: none, log, minmax, quantile, power, standard, robust\n",
            "Transform method [none]: quantile\n",
            "Enable color mapping? (y/n) [y]: y\n",
            "Invert colormap? (y/n) [n]: y\n",
            "Enable transparency mapping? (y/n) [n]: n\n",
            "\n",
            "--- Per-file Model/Chain Configuration ---\n",
            "Current assignments:\n",
            "  1. PB2: #1/b\n",
            "  2. PA: #1/c\n",
            "  3. PB1: #1/a\n",
            "\n",
            "Edit model/chain assignments? (y/n) [n]: n\n",
            "\n",
            "=== Configuration Summary ===\n",
            "Colormap: RdBu, Transform: quantile\n",
            "Color: True (invert=True), Transparency: False (invert=False)\n",
            "Mode: Multi-file normalization\n",
            "  - PB2: #1/b\n",
            "  - PA: #1/c\n",
            "  - PB1: #1/a\n"
          ]
        }
      ],
      "source": [
        "# --- Interactive Configuration ---\n",
        "\n",
        "# Shared settings (apply to all files)\n",
        "if ENTROPY_FORMAT == \"wide\" and value_columns:\n",
        "    print(f\"Value columns: {value_columns}\")\n",
        "\n",
        "CMAP_NAME = input(\"Colormap name [Greys]: \").strip() or \"Greys\"\n",
        "\n",
        "print(\"Transform methods: none, log, minmax, quantile, power, standard, robust\")\n",
        "TRANSFORM_METHOD = input(\"Transform method [none]: \").strip() or \"none\"\n",
        "\n",
        "_color = input(\"Enable color mapping? (y/n) [y]: \").strip().lower()\n",
        "COLOR = _color not in (\"n\", \"no\")\n",
        "\n",
        "COLOR_INVERT = False\n",
        "if COLOR:\n",
        "    _ci = input(\"Invert colormap? (y/n) [n]: \").strip().lower()\n",
        "    COLOR_INVERT = _ci in (\"y\", \"yes\")\n",
        "\n",
        "_trans = input(\"Enable transparency mapping? (y/n) [n]: \").strip().lower()\n",
        "TRANSPARENCY = _trans in (\"y\", \"yes\")\n",
        "\n",
        "TRANSPARENCY_INVERT = False\n",
        "if TRANSPARENCY:\n",
        "    _ti = input(\"Invert transparency? (y/n) [n]: \").strip().lower()\n",
        "    TRANSPARENCY_INVERT = _ti in (\"y\", \"yes\")\n",
        "\n",
        "# Model/chain configuration depends on mode\n",
        "if MULTI_FILE_MODE and all_entropy_data:\n",
        "    # Multi-file mode: model/chain already set per file, allow editing\n",
        "    print(\"\\n--- Per-file Model/Chain Configuration ---\")\n",
        "    print(\"Current assignments:\")\n",
        "    for i, data in enumerate(all_entropy_data):\n",
        "        spec = f\"#{data['model']}\" + (f\"/{data['chain']}\" if data['chain'] else \"\")\n",
        "        print(f\"  {i+1}. {data['label']}: {spec}\")\n",
        "\n",
        "    _edit = input(\"\\nEdit model/chain assignments? (y/n) [n]: \").strip().lower()\n",
        "    if _edit in (\"y\", \"yes\"):\n",
        "        for i, data in enumerate(all_entropy_data):\n",
        "            print(f\"\\n{data['label']} (currently #{data['model']}\" + (f\"/{data['chain']}\" if data['chain'] else \"\") + \"):\")\n",
        "            _model = input(f\"  Model ID [{data['model']}]: \").strip()\n",
        "            if _model:\n",
        "                data['model'] = int(_model)\n",
        "            _chain = input(f\"  Chain ID [{data['chain'] or 'none'}]: \").strip()\n",
        "            if _chain.lower() == 'none':\n",
        "                data['chain'] = \"\"\n",
        "            elif _chain:\n",
        "                data['chain'] = _chain\n",
        "\n",
        "        print(\"\\nUpdated assignments:\")\n",
        "        for i, data in enumerate(all_entropy_data):\n",
        "            spec = f\"#{data['model']}\" + (f\"/{data['chain']}\" if data['chain'] else \"\")\n",
        "            print(f\"  {i+1}. {data['label']}: {spec}\")\n",
        "\n",
        "    # These are not used in multi-file mode but define for consistency\n",
        "    MODEL = None\n",
        "    CHAIN = None\n",
        "else:\n",
        "    # Single-file mode: one model/chain for all\n",
        "    _model = input(\"Model ID [1]: \").strip() or \"1\"\n",
        "    MODEL = int(_model)\n",
        "    CHAIN = input(\"Chain ID (e.g. A, B — leave blank for none): \").strip()\n",
        "\n",
        "# Summary\n",
        "print(f\"\\n=== Configuration Summary ===\")\n",
        "print(f\"Colormap: {CMAP_NAME}, Transform: {TRANSFORM_METHOD}\")\n",
        "print(f\"Color: {COLOR} (invert={COLOR_INVERT}), Transparency: {TRANSPARENCY} (invert={TRANSPARENCY_INVERT})\")\n",
        "\n",
        "if MULTI_FILE_MODE and all_entropy_data:\n",
        "    print(\"Mode: Multi-file normalization\")\n",
        "    for data in all_entropy_data:\n",
        "        spec = f\"#{data['model']}\" + (f\"/{data['chain']}\" if data['chain'] else \"\")\n",
        "        print(f\"  - {data['label']}: {spec}\")\n",
        "else:\n",
        "    print(f\"Mode: Single-file\")\n",
        "    print(f\"Model: #{MODEL}\" + (f\"/{CHAIN}\" if CHAIN else \"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3b. Configure value cutoffs (optional)\n",
        "\n",
        "After transformation, you can filter which residues are included in the CXC output\n",
        "based on their transformed values.\n",
        "\n",
        "**For quantile (rank-based) transforms:**\n",
        "- Values are ordinal ranks from 0 to 1\n",
        "- Specify rank ranges like `0-0.25` (bottom quartile) or `0.75-1.0` (top quartile)\n",
        "- Multiple ranges: `0-0.1, 0.9-1.0` (extreme 10% on both ends)\n",
        "\n",
        "**For other transforms (log, power, standard, robust, minmax, none):**\n",
        "- Values are continuous (rational numbers)\n",
        "- Statistics (mean, std, min, max) are displayed to help choose cutoffs\n",
        "- Specify value ranges based on the transformed values"
      ],
      "metadata": {
        "id": "txoTxGrwJV-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Value Cutoff Configuration ---\n",
        "# This cell computes statistics on transformed values and allows filtering\n",
        "\n",
        "# Dictionary to store masks: key = seq_id or index, value = boolean mask array\n",
        "residue_masks = {}\n",
        "USE_CUTOFFS = False\n",
        "\n",
        "_use_cutoffs = input(\"Apply value cutoffs to filter residues? (y/n) [n]: \").strip().lower()\n",
        "USE_CUTOFFS = _use_cutoffs in (\"y\", \"yes\")\n",
        "\n",
        "if USE_CUTOFFS:\n",
        "    is_rank_based = TRANSFORM_METHOD == \"quantile\"\n",
        "\n",
        "    if is_rank_based:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"QUANTILE TRANSFORM (Rank-based)\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"Values are ordinal ranks from 0 (lowest) to 1 (highest).\")\n",
        "        print(\"\\nExamples of rank range specifications:\")\n",
        "        print(\"  0-0.25        : Bottom quartile (lowest 25%)\")\n",
        "        print(\"  0.75-1.0      : Top quartile (highest 25%)\")\n",
        "        print(\"  0-0.1, 0.9-1.0: Extreme 10% on both ends\")\n",
        "        print(\"  0.25-0.75     : Middle 50% (interquartile range)\")\n",
        "        print(\"  all           : Include all residues (no filtering)\")\n",
        "    else:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"TRANSFORM: {TRANSFORM_METHOD.upper() if TRANSFORM_METHOD != 'none' else 'NONE (raw values)'}\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"Values are continuous. Statistics are shown to help choose cutoffs.\")\n",
        "        print(\"\\nExamples of value range specifications:\")\n",
        "        print(\"  -1.5-0.5      : Values between -1.5 and 0.5\")\n",
        "        print(\"  0-2, 5-10     : Multiple ranges (0 to 2 OR 5 to 10)\")\n",
        "        print(\"  all           : Include all residues (no filtering)\")\n",
        "\n",
        "    # --- Multi-file mode ---\n",
        "    if MULTI_FILE_MODE and all_entropy_data:\n",
        "        # Fit transform scaler on combined data for consistent statistics\n",
        "        combined_values = np.concatenate([d[\"values\"] for d in all_entropy_data])\n",
        "        transform_scaler_for_stats = fit_scaler(combined_values, method=TRANSFORM_METHOD)\n",
        "\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(\"COMBINED STATISTICS (all files)\")\n",
        "        print(\"-\"*60)\n",
        "        combined_stats = compute_value_statistics(\n",
        "            combined_values,\n",
        "            transform_method=TRANSFORM_METHOD,\n",
        "            transform_scaler=transform_scaler_for_stats,\n",
        "        )\n",
        "        combined_stats[\"transform_method\"] = TRANSFORM_METHOD\n",
        "        print(display_statistics_summary(combined_stats, label=\"All Files Combined\"))\n",
        "\n",
        "        # Show per-file statistics\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(\"PER-FILE STATISTICS\")\n",
        "        print(\"-\"*60)\n",
        "        for i, data in enumerate(all_entropy_data):\n",
        "            stats = compute_value_statistics(\n",
        "                data[\"values\"],\n",
        "                transform_method=TRANSFORM_METHOD,\n",
        "                transform_scaler=transform_scaler_for_stats,\n",
        "            )\n",
        "            stats[\"transform_method\"] = TRANSFORM_METHOD\n",
        "            print(f\"\\n{i+1}. {data['label']} ({data['seq_id']}):\")\n",
        "            print(f\"   Residues: {stats['n_residues']}\")\n",
        "            print(f\"   Range: {stats['min']:.4f} - {stats['max']:.4f}\")\n",
        "            print(f\"   Mean: {stats['mean']:.4f}, Std: {stats['std']:.4f}\")\n",
        "            # Store transformed values for filtering\n",
        "            data[\"transformed_values\"] = stats[\"transformed_values\"]\n",
        "\n",
        "        # Ask for range specification\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(\"SPECIFY CUTOFF RANGES\")\n",
        "        print(\"-\"*60)\n",
        "\n",
        "        _same_range = input(\"Use same range for all files? (y/n) [y]: \").strip().lower()\n",
        "        use_same_range = _same_range not in (\"n\", \"no\")\n",
        "\n",
        "        if use_same_range:\n",
        "            if is_rank_based:\n",
        "                range_str = input(\"Rank range(s) for all files [all]: \").strip() or \"all\"\n",
        "            else:\n",
        "                range_str = input(\"Value range(s) for all files [all]: \").strip() or \"all\"\n",
        "\n",
        "            try:\n",
        "                ranges = parse_range_string(range_str)\n",
        "                if ranges:\n",
        "                    print(f\"\\nApplying ranges: {ranges}\")\n",
        "                    for data in all_entropy_data:\n",
        "                        mask = create_value_mask(data[\"transformed_values\"], ranges)\n",
        "                        residue_masks[data[\"seq_id\"]] = mask\n",
        "                        included = np.sum(mask)\n",
        "                        print(f\"  {data['label']}: {included}/{len(mask)} residues included ({100*included/len(mask):.1f}%)\")\n",
        "                else:\n",
        "                    print(\"\\nNo filtering - all residues will be included.\")\n",
        "            except ValueError as e:\n",
        "                print(f\"Error parsing range: {e}\")\n",
        "                print(\"No filtering will be applied.\")\n",
        "        else:\n",
        "            # Per-file range specification\n",
        "            for data in all_entropy_data:\n",
        "                print(f\"\\n{data['label']} ({data['seq_id']}):\")\n",
        "                if is_rank_based:\n",
        "                    range_str = input(f\"  Rank range(s) [all]: \").strip() or \"all\"\n",
        "                else:\n",
        "                    range_str = input(f\"  Value range(s) [all]: \").strip() or \"all\"\n",
        "\n",
        "                try:\n",
        "                    ranges = parse_range_string(range_str)\n",
        "                    if ranges:\n",
        "                        mask = create_value_mask(data[\"transformed_values\"], ranges)\n",
        "                        residue_masks[data[\"seq_id\"]] = mask\n",
        "                        included = np.sum(mask)\n",
        "                        print(f\"    -> {included}/{len(mask)} residues included ({100*included/len(mask):.1f}%)\")\n",
        "                    else:\n",
        "                        print(f\"    -> All residues included (no filtering)\")\n",
        "                except ValueError as e:\n",
        "                    print(f\"    Error: {e}. No filtering for this file.\")\n",
        "\n",
        "    # --- Single-file mode: per-residue format ---\n",
        "    elif ENTROPY_FORMAT == \"per_residue\":\n",
        "        values = per_residue_info[\"values\"]\n",
        "        stats = compute_value_statistics(values, transform_method=TRANSFORM_METHOD)\n",
        "        stats[\"transform_method\"] = TRANSFORM_METHOD\n",
        "        print(\"\\n\" + display_statistics_summary(stats, label=per_residue_info[\"label\"]))\n",
        "\n",
        "        # Store transformed values\n",
        "        per_residue_info[\"transformed_values\"] = stats[\"transformed_values\"]\n",
        "\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        if is_rank_based:\n",
        "            range_str = input(\"Rank range(s) to include [all]: \").strip() or \"all\"\n",
        "        else:\n",
        "            range_str = input(\"Value range(s) to include [all]: \").strip() or \"all\"\n",
        "\n",
        "        try:\n",
        "            ranges = parse_range_string(range_str)\n",
        "            if ranges:\n",
        "                mask = create_value_mask(stats[\"transformed_values\"], ranges)\n",
        "                residue_masks[per_residue_info[\"seq_id\"]] = mask\n",
        "                included = np.sum(mask)\n",
        "                print(f\"-> {included}/{len(mask)} residues included ({100*included/len(mask):.1f}%)\")\n",
        "            else:\n",
        "                print(\"-> All residues included (no filtering)\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error parsing range: {e}\")\n",
        "            print(\"No filtering will be applied.\")\n",
        "\n",
        "    # --- Single-file mode: wide format ---\n",
        "    elif ENTROPY_FORMAT == \"wide\":\n",
        "        print(\"\\nComputing statistics for each sequence...\")\n",
        "\n",
        "        for _, row in df_merged.iterrows():\n",
        "            seq_id = row[\"sequence_id\"]\n",
        "            label = row.get(\"name\", seq_id) or seq_id\n",
        "            values = row[value_columns].values.astype(float)\n",
        "\n",
        "            stats = compute_value_statistics(values, transform_method=TRANSFORM_METHOD)\n",
        "            stats[\"transform_method\"] = TRANSFORM_METHOD\n",
        "            print(f\"\\n{label} ({seq_id}):\")\n",
        "            print(f\"  Residues: {stats['n_residues']}\")\n",
        "            print(f\"  Range: {stats['min']:.4f} - {stats['max']:.4f}\")\n",
        "            print(f\"  Mean: {stats['mean']:.4f}, Std: {stats['std']:.4f}\")\n",
        "\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        _same_range = input(\"Use same range for all sequences? (y/n) [y]: \").strip().lower()\n",
        "        use_same_range = _same_range not in (\"n\", \"no\")\n",
        "\n",
        "        if use_same_range:\n",
        "            if is_rank_based:\n",
        "                range_str = input(\"Rank range(s) for all sequences [all]: \").strip() or \"all\"\n",
        "            else:\n",
        "                range_str = input(\"Value range(s) for all sequences [all]: \").strip() or \"all\"\n",
        "\n",
        "            try:\n",
        "                ranges = parse_range_string(range_str)\n",
        "                if ranges:\n",
        "                    print(f\"\\nApplying ranges: {ranges}\")\n",
        "                    for _, row in df_merged.iterrows():\n",
        "                        seq_id = row[\"sequence_id\"]\n",
        "                        values = row[value_columns].values.astype(float)\n",
        "                        transformed = scale_values(values, method=TRANSFORM_METHOD)\n",
        "                        mask = create_value_mask(transformed, ranges)\n",
        "                        residue_masks[seq_id] = mask\n",
        "                        included = np.sum(mask)\n",
        "                        print(f\"  {seq_id}: {included}/{len(mask)} residues ({100*included/len(mask):.1f}%)\")\n",
        "                else:\n",
        "                    print(\"\\nNo filtering - all residues will be included.\")\n",
        "            except ValueError as e:\n",
        "                print(f\"Error parsing range: {e}\")\n",
        "        else:\n",
        "            for _, row in df_merged.iterrows():\n",
        "                seq_id = row[\"sequence_id\"]\n",
        "                label = row.get(\"name\", seq_id) or seq_id\n",
        "                values = row[value_columns].values.astype(float)\n",
        "\n",
        "                print(f\"\\n{label} ({seq_id}):\")\n",
        "                if is_rank_based:\n",
        "                    range_str = input(f\"  Rank range(s) [all]: \").strip() or \"all\"\n",
        "                else:\n",
        "                    range_str = input(f\"  Value range(s) [all]: \").strip() or \"all\"\n",
        "\n",
        "                try:\n",
        "                    ranges = parse_range_string(range_str)\n",
        "                    if ranges:\n",
        "                        transformed = scale_values(values, method=TRANSFORM_METHOD)\n",
        "                        mask = create_value_mask(transformed, ranges)\n",
        "                        residue_masks[seq_id] = mask\n",
        "                        included = np.sum(mask)\n",
        "                        print(f\"    -> {included}/{len(mask)} residues ({100*included/len(mask):.1f}%)\")\n",
        "                    else:\n",
        "                        print(f\"    -> All residues included\")\n",
        "                except ValueError as e:\n",
        "                    print(f\"    Error: {e}\")\n",
        "\n",
        "    # Summary\n",
        "    if residue_masks:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"CUTOFF SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        total_residues = sum(len(m) for m in residue_masks.values())\n",
        "        total_included = sum(np.sum(m) for m in residue_masks.values())\n",
        "        print(f\"Total: {total_included}/{total_residues} residues will be included ({100*total_included/total_residues:.1f}%)\")\n",
        "    else:\n",
        "        print(\"\\nNo cutoffs applied - all residues will be included.\")\n",
        "else:\n",
        "    print(\"Cutoffs disabled - all residues will be included in CXC output.\")"
      ],
      "metadata": {
        "id": "gNV3G5gcJV-g",
        "outputId": "deaa00af-fa25-452a-cb04-6189a088d1ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apply value cutoffs to filter residues? (y/n) [n]: y\n",
            "\n",
            "============================================================\n",
            "QUANTILE TRANSFORM (Rank-based)\n",
            "============================================================\n",
            "Values are ordinal ranks from 0 (lowest) to 1 (highest).\n",
            "\n",
            "Examples of rank range specifications:\n",
            "  0-0.25        : Bottom quartile (lowest 25%)\n",
            "  0.75-1.0      : Top quartile (highest 25%)\n",
            "  0-0.1, 0.9-1.0: Extreme 10% on both ends\n",
            "  0.25-0.75     : Middle 50% (interquartile range)\n",
            "  all           : Include all residues (no filtering)\n",
            "\n",
            "------------------------------------------------------------\n",
            "COMBINED STATISTICS (all files)\n",
            "------------------------------------------------------------\n",
            "=== Statistics for All Files Combined ===\n",
            "Transform type: Quantile (rank-based, ordinal values 0-1)\n",
            "  Residues: 2238\n",
            "  Rank range: 0.0000 - 1.0000\n",
            "  Quartiles:\n",
            "    Q1 (25%): 0.2633\n",
            "    Q2 (50%): 0.5435\n",
            "    Q3 (75%): 0.7477\n",
            "\n",
            "  Suggested rank ranges:\n",
            "    Bottom quartile: 0-0.25\n",
            "    Middle 50%: 0.25-0.75\n",
            "    Top quartile: 0.75-1.0\n",
            "\n",
            "------------------------------------------------------------\n",
            "PER-FILE STATISTICS\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. PB2 (2e51a71e2288):\n",
            "   Residues: 761\n",
            "   Range: 0.0029 - 0.9905\n",
            "   Mean: 0.4554, Std: 0.2596\n",
            "\n",
            "2. PA (2d720887d514):\n",
            "   Residues: 718\n",
            "   Range: 0.0048 - 0.9990\n",
            "   Mean: 0.5802, Std: 0.2639\n",
            "\n",
            "3. PB1 (0ea58344488f):\n",
            "   Residues: 759\n",
            "   Range: 0.0000 - 1.0000\n",
            "   Mean: 0.4689, Std: 0.3193\n",
            "\n",
            "------------------------------------------------------------\n",
            "SPECIFY CUTOFF RANGES\n",
            "------------------------------------------------------------\n",
            "Use same range for all files? (y/n) [y]: y\n",
            "Rank range(s) for all files [all]: 0.9-1.0\n",
            "\n",
            "Applying ranges: [(0.9, 1.0)]\n",
            "  PB2: 22/761 residues included (2.9%)\n",
            "  PA: 75/718 residues included (10.4%)\n",
            "  PB1: 78/759 residues included (10.3%)\n",
            "\n",
            "============================================================\n",
            "CUTOFF SUMMARY\n",
            "============================================================\n",
            "Total: 175/2238 residues will be included (7.8%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYrwjdYFaeQo"
      },
      "source": [
        "## 4. Generate `.cxc` scripts (one per sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVaYSPPjaeQo",
        "outputId": "3b3bdaa0-a28e-4373-987d-43245f0e0619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Multi-file normalization ===\n",
            "Combined 3 files: 2238 total residues\n",
            "  Min: 0.0114, Max: 2.9531\n",
            "  Mean: 2.7674, Std: 0.2586\n",
            "Fitted scalers on combined data (transform=quantile)\n",
            "Applying cutoff filters to 3 file(s)\n",
            "\n",
            "  Created: cxc_output/PB2_2e51a71e2288_1b_RdBu_i_quantile_multifile_filtered.cxc (#1/b) [22/761 residues]\n",
            "  Created: cxc_output/PA_2d720887d514_1c_RdBu_i_quantile_multifile_filtered.cxc (#1/c) [75/718 residues]\n",
            "  Created: cxc_output/PB1_0ea58344488f_1a_RdBu_i_quantile_multifile_filtered.cxc (#1/a) [78/759 residues]\n",
            "\n",
            "Generated 3 .cxc file(s).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = \"cxc_output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "generated_files = []\n",
        "\n",
        "def _make_cxc(values, label, seq_id, model, chain, mask=None):\n",
        "    \"\"\"Generate a .cxc file for one sequence (single-file mode).\"\"\"\n",
        "    script = generate_chimerax_script(\n",
        "        values,\n",
        "        cmap_name=CMAP_NAME,\n",
        "        transform_method=TRANSFORM_METHOD,\n",
        "        color=COLOR,\n",
        "        color_invert=COLOR_INVERT,\n",
        "        transparency=TRANSPARENCY,\n",
        "        transparency_invert=TRANSPARENCY_INVERT,\n",
        "        model=model,\n",
        "        chain=chain,\n",
        "        residue_mask=mask,\n",
        "    )\n",
        "    safe_label = str(label).replace(\" \", \"_\").replace(\"/\", \"_\")\n",
        "    chain_str = chain if chain else \"\"\n",
        "    cmap_str = f\"{CMAP_NAME}_i\" if COLOR_INVERT else CMAP_NAME\n",
        "    # Add \"filtered\" suffix if mask is applied\n",
        "    filter_str = \"_filtered\" if mask is not None and not np.all(mask) else \"\"\n",
        "    out_path = os.path.join(output_dir, f\"{safe_label}_{seq_id}_{model}{chain_str}_{cmap_str}_{TRANSFORM_METHOD}{filter_str}.cxc\")\n",
        "    write_chimerax_script(script, out_path)\n",
        "    return out_path\n",
        "\n",
        "def _make_cxc_with_scalers(values, label, seq_id, model, chain, transform_scaler, minmax_scaler, mask=None):\n",
        "    \"\"\"Generate a .cxc file using pre-fitted scalers (multi-file mode).\"\"\"\n",
        "    script = generate_chimerax_script_with_scalers(\n",
        "        values,\n",
        "        transform_scaler=transform_scaler,\n",
        "        minmax_scaler=minmax_scaler,\n",
        "        cmap_name=CMAP_NAME,\n",
        "        color=COLOR,\n",
        "        color_invert=COLOR_INVERT,\n",
        "        transparency=TRANSPARENCY,\n",
        "        transparency_invert=TRANSPARENCY_INVERT,\n",
        "        model=model,\n",
        "        chain=chain,\n",
        "        residue_mask=mask,\n",
        "    )\n",
        "    safe_label = str(label).replace(\" \", \"_\").replace(\"/\", \"_\")\n",
        "    chain_str = chain if chain else \"\"\n",
        "    cmap_str = f\"{CMAP_NAME}_i\" if COLOR_INVERT else CMAP_NAME\n",
        "    # Add \"filtered\" suffix if mask is applied\n",
        "    filter_str = \"_filtered\" if mask is not None and not np.all(mask) else \"\"\n",
        "    out_path = os.path.join(output_dir, f\"{safe_label}_{seq_id}_{model}{chain_str}_{cmap_str}_{TRANSFORM_METHOD}_multifile{filter_str}.cxc\")\n",
        "    write_chimerax_script(script, out_path)\n",
        "    return out_path\n",
        "\n",
        "# --- Multi-file mode: fit scalers on combined data ---\n",
        "if MULTI_FILE_MODE and all_entropy_data:\n",
        "    print(\"=== Multi-file normalization ===\")\n",
        "\n",
        "    # Combine all values\n",
        "    combined_values = np.concatenate([d[\"values\"] for d in all_entropy_data])\n",
        "    print(f\"Combined {len(all_entropy_data)} files: {len(combined_values)} total residues\")\n",
        "    print(f\"  Min: {combined_values.min():.4f}, Max: {combined_values.max():.4f}\")\n",
        "    print(f\"  Mean: {combined_values.mean():.4f}, Std: {combined_values.std():.4f}\")\n",
        "\n",
        "    # Fit transform scaler on combined data\n",
        "    transform_scaler = fit_scaler(combined_values, method=TRANSFORM_METHOD)\n",
        "\n",
        "    # Apply transform to combined data, then fit minmax scaler\n",
        "    if transform_scaler is not None:\n",
        "        scaled_combined = scale_values_with_scaler(combined_values, transform_scaler)\n",
        "    else:\n",
        "        scaled_combined = combined_values\n",
        "\n",
        "    minmax_scaler = fit_minmax_scaler(scaled_combined)\n",
        "    print(f\"Fitted scalers on combined data (transform={TRANSFORM_METHOD})\")\n",
        "\n",
        "    if residue_masks:\n",
        "        print(f\"Applying cutoff filters to {len(residue_masks)} file(s)\\n\")\n",
        "    else:\n",
        "        print(\"No cutoff filters applied\\n\")\n",
        "\n",
        "    # Generate .cxc for each sequence using the shared scalers and per-file model/chain\n",
        "    for data in all_entropy_data:\n",
        "        # Get mask for this sequence if available\n",
        "        mask = residue_masks.get(data[\"seq_id\"], None)\n",
        "\n",
        "        out_path = _make_cxc_with_scalers(\n",
        "            data[\"values\"],\n",
        "            data[\"label\"],\n",
        "            data[\"seq_id\"],\n",
        "            data[\"model\"],\n",
        "            data[\"chain\"],\n",
        "            transform_scaler,\n",
        "            minmax_scaler,\n",
        "            mask=mask,\n",
        "        )\n",
        "        generated_files.append(out_path)\n",
        "        spec = f\"#{data['model']}\" + (f\"/{data['chain']}\" if data['chain'] else \"\")\n",
        "        if mask is not None and not np.all(mask):\n",
        "            included = np.sum(mask)\n",
        "            print(f\"  Created: {out_path} ({spec}) [{included}/{len(mask)} residues]\")\n",
        "        else:\n",
        "            print(f\"  Created: {out_path} ({spec})\")\n",
        "\n",
        "# --- Single-file mode ---\n",
        "elif ENTROPY_FORMAT == \"wide\":\n",
        "    # One row per sequence -- iterate over df_merged\n",
        "    for _, row in df_merged.iterrows():\n",
        "        seq_id = row[\"sequence_id\"]\n",
        "        label = row.get(\"name\", seq_id) or seq_id\n",
        "        values = row[value_columns].values.astype(float)\n",
        "\n",
        "        # Get mask for this sequence if available\n",
        "        mask = residue_masks.get(seq_id, None)\n",
        "\n",
        "        out_path = _make_cxc(values, label, seq_id, MODEL, CHAIN, mask=mask)\n",
        "        generated_files.append(out_path)\n",
        "        if mask is not None and not np.all(mask):\n",
        "            included = np.sum(mask)\n",
        "            print(f\"  Created: {out_path} [{included}/{len(mask)} residues]\")\n",
        "        else:\n",
        "            print(f\"  Created: {out_path}\")\n",
        "else:\n",
        "    # Per-residue format -- single sequence\n",
        "    # Get mask for this sequence if available\n",
        "    mask = residue_masks.get(per_residue_info[\"seq_id\"], None)\n",
        "\n",
        "    out_path = _make_cxc(\n",
        "        per_residue_info[\"values\"],\n",
        "        per_residue_info[\"label\"],\n",
        "        per_residue_info[\"seq_id\"],\n",
        "        MODEL,\n",
        "        CHAIN,\n",
        "        mask=mask,\n",
        "    )\n",
        "    generated_files.append(out_path)\n",
        "    if mask is not None and not np.all(mask):\n",
        "        included = np.sum(mask)\n",
        "        print(f\"  Created: {out_path} [{included}/{len(mask)} residues]\")\n",
        "    else:\n",
        "        print(f\"  Created: {out_path}\")\n",
        "\n",
        "print(f\"\\nGenerated {len(generated_files)} .cxc file(s).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15_ECcEKaeQo"
      },
      "source": [
        "## 5. Download `.cxc` files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PKEKsbxJaeQo",
        "outputId": "5b7cc66e-1d59-4611-b00a-81dfccc3f972"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f92e1bd-fde1-4ffe-a52d-1642654354ce\", \"PB2_2e51a71e2288_1b_RdBu_i_quantile_multifile_filtered.cxc\", 1170)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5047e409-d0f7-40c3-9fff-930ba59b2062\", \"PA_2d720887d514_1c_RdBu_i_quantile_multifile_filtered.cxc\", 3912)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_77c1966e-7057-4505-b725-3740e1551758\", \"PB1_0ea58344488f_1a_RdBu_i_quantile_multifile_filtered.cxc\", 4051)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for f in generated_files:\n",
        "    files.download(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8HDGbCTV8s7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
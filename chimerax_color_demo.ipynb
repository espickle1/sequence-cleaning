{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChimeraX Color Script Generator\n",
    "\n",
    "Upload per-residue entropy (or any scalar) values, sequences, and metadata.\n",
    "This notebook generates a `.cxc` ChimeraX color script **per sequence** and\n",
    "downloads them to your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup – Clone repo & install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "repo_dir = \"sequence-cleaning\"\n",
    "if not os.path.isdir(repo_dir):\n",
    "    subprocess.run(\n",
    "        [\"git\", \"clone\", \"https://github.com/espickle1/sequence-cleaning.git\"],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "if os.path.basename(os.getcwd()) != repo_dir:\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "from analysis.chimerax_color_lib import generate_chimerax_script, write_chimerax_script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Upload files\n\nUpload three CSV files:\n- **Entropy file** – per-residue entropy values. Expected columns: `sequence_id` plus one or more value columns, **or** a single per-residue file (e.g. `residue_position, entropy, ...`) that applies to one sequence.\n- **Sequences file** – must contain `sequence_id` and `sequence` columns.\n- **Metadata file** – must contain `sequence_id` and `name` columns."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Upload the ENTROPY file (.csv):\")\nentropy_upload = files.upload()\nentropy_filename = list(entropy_upload.keys())[0]\ndf_entropy = pd.read_csv(entropy_filename)\nprint(f\"Loaded {entropy_filename}: {df_entropy.shape}\")\nprint(f\"Columns: {list(df_entropy.columns)}\")\ndf_entropy.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Upload the SEQUENCES file (.csv):\")\nseq_upload = files.upload()\nseq_filename = list(seq_upload.keys())[0]\ndf_sequences = pd.read_csv(seq_filename)\nprint(f\"Loaded {seq_filename}: {df_sequences.shape}\")\nprint(f\"Columns: {list(df_sequences.columns)}\")\ndf_sequences.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Upload the METADATA file (.csv):\")\nmeta_upload = files.upload()\nmeta_filename = list(meta_upload.keys())[0]\ndf_metadata = pd.read_csv(meta_filename)\nprint(f\"Loaded {meta_filename}: {df_metadata.shape}\")\nprint(f\"Columns: {list(df_metadata.columns)}\")\ndf_metadata.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge files on `sequence_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Detect entropy file format and build a unified structure\n#\n# Format A: Wide table with sequence_id + value columns (one row per sequence)\n# Format B: Per-residue table (residue_position, entropy, ...) for a single sequence\n#           In this case sequence_id is extracted from the filename.\n\nif \"sequence_id\" in df_entropy.columns:\n    # Format A -- entropy file already has sequence_id\n    merge_cols = [\"sequence_id\", \"sequence\"]\n    if \"sequence\" in df_sequences.columns:\n        df_merged = df_entropy.merge(\n            df_sequences[merge_cols], on=\"sequence_id\", how=\"inner\"\n        )\n    else:\n        df_merged = df_entropy.copy()\n\n    if \"name\" in df_metadata.columns:\n        df_merged = df_merged.merge(\n            df_metadata[[\"sequence_id\", \"name\"]], on=\"sequence_id\", how=\"left\"\n        )\n\n    value_columns = [\n        c for c in df_entropy.columns if c != \"sequence_id\"\n    ]\n    print(f\"Format A detected (wide table). Value columns: {value_columns}\")\n    print(f\"Merged rows: {len(df_merged)}\")\n    display(df_merged.head())\n    ENTROPY_FORMAT = \"wide\"\n\nelse:\n    # Format B -- per-residue file without sequence_id\n    # Try to extract sequence_id from the entropy filename\n    # Pipeline exports files named like: entropy_per_residue_{seq_id}.csv\n    import re\n    match = re.search(r\"entropy_per_residue_(.+)\\.csv\", entropy_filename)\n    if match:\n        inferred_seq_id = match.group(1)\n    else:\n        inferred_seq_id = Path(entropy_filename).stem\n\n    print(f\"Format B detected (per-residue). Inferred sequence_id: {inferred_seq_id}\")\n\n    # Determine which column holds the values\n    if \"entropy\" in df_entropy.columns:\n        value_col = \"entropy\"\n    else:\n        # Use the first numeric column that isn't residue_position\n        numeric_cols = [\n            c for c in df_entropy.select_dtypes(include=\"number\").columns\n            if c != \"residue_position\"\n        ]\n        value_col = numeric_cols[0] if numeric_cols else df_entropy.columns[-1]\n\n    print(f\"Using value column: '{value_col}'\")\n    print(f\"Residues: {len(df_entropy)}\")\n\n    # Look up the name from metadata\n    label = inferred_seq_id\n    if \"name\" in df_metadata.columns and \"sequence_id\" in df_metadata.columns:\n        name_match = df_metadata.loc[\n            df_metadata[\"sequence_id\"] == inferred_seq_id, \"name\"\n        ]\n        if len(name_match):\n            label = name_match.iloc[0]\n\n    # Store for the generation step\n    df_merged = None\n    per_residue_info = {\n        \"seq_id\": inferred_seq_id,\n        \"label\": label,\n        \"values\": df_entropy[value_col].values.astype(float),\n    }\n    value_columns = None\n    ENTROPY_FORMAT = \"per_residue\"\n    display(df_entropy.head())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure color mapping\n",
    "\n",
    "Adjust these parameters as needed before generating the scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- Interactive Configuration ---\nif ENTROPY_FORMAT == \"wide\" and value_columns:\n    print(f\"Value columns: {value_columns}\")\n\nCMAP_NAME = input(\"Colormap name [Greys]: \").strip() or \"Greys\"\n\nprint(\"Transform methods: none, quantile, power, standard, robust\")\nTRANSFORM_METHOD = input(\"Transform method [none]: \").strip() or \"none\"\n\n_color = input(\"Enable color mapping? (y/n) [y]: \").strip().lower()\nCOLOR = _color not in (\"n\", \"no\")\n\nCOLOR_INVERT = False\nif COLOR:\n    _ci = input(\"Invert colormap? (y/n) [n]: \").strip().lower()\n    COLOR_INVERT = _ci in (\"y\", \"yes\")\n\n_trans = input(\"Enable transparency mapping? (y/n) [n]: \").strip().lower()\nTRANSPARENCY = _trans in (\"y\", \"yes\")\n\nTRANSPARENCY_INVERT = False\nif TRANSPARENCY:\n    _ti = input(\"Invert transparency? (y/n) [n]: \").strip().lower()\n    TRANSPARENCY_INVERT = _ti in (\"y\", \"yes\")\n\n_model = input(\"Model ID [1]: \").strip() or \"1\"\nMODEL = int(_model)\n\nCHAIN = input(\"Chain ID (e.g. A, B — leave blank for none): \").strip()\n\nprint(f\"\\nColormap: {CMAP_NAME}, Transform: {TRANSFORM_METHOD}\")\nprint(f\"Color: {COLOR} (invert={COLOR_INVERT}), Transparency: {TRANSPARENCY} (invert={TRANSPARENCY_INVERT})\")\nprint(f\"Model: #{MODEL}\" + (f\"/{CHAIN}\" if CHAIN else \"\"))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate `.cxc` scripts (one per sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\noutput_dir = \"cxc_output\"\nos.makedirs(output_dir, exist_ok=True)\n\ngenerated_files = []\n\ndef _make_cxc(values, label, seq_id):\n    \"\"\"Generate a .cxc file for one sequence and return the output path.\"\"\"\n    script = generate_chimerax_script(\n        values,\n        cmap_name=CMAP_NAME,\n        transform_method=TRANSFORM_METHOD,\n        color=COLOR,\n        color_invert=COLOR_INVERT,\n        transparency=TRANSPARENCY,\n        transparency_invert=TRANSPARENCY_INVERT,\n        model=MODEL,\n        chain=CHAIN,\n    )\n    safe_label = str(label).replace(\" \", \"_\").replace(\"/\", \"_\")\n    out_path = os.path.join(output_dir, f\"{safe_label}_{seq_id}.cxc\")\n    write_chimerax_script(script, out_path)\n    return out_path\n\nif ENTROPY_FORMAT == \"wide\":\n    # One row per sequence -- iterate over df_merged\n    for _, row in df_merged.iterrows():\n        seq_id = row[\"sequence_id\"]\n        label = row.get(\"name\", seq_id) or seq_id\n        values = row[value_columns].values.astype(float)\n\n        out_path = _make_cxc(values, label, seq_id)\n        generated_files.append(out_path)\n        print(f\"  Created: {out_path}\")\nelse:\n    # Per-residue format -- single sequence\n    out_path = _make_cxc(\n        per_residue_info[\"values\"],\n        per_residue_info[\"label\"],\n        per_residue_info[\"seq_id\"],\n    )\n    generated_files.append(out_path)\n    print(f\"  Created: {out_path}\")\n\nprint(f\"\\nGenerated {len(generated_files)} .cxc file(s).\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download `.cxc` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in generated_files:\n",
    "    files.download(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
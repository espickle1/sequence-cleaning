{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ ESMC Protein Embedding Generator\n",
    "\n",
    "Generate protein sequence embeddings using ESM-C models from EvolutionaryScale.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**Before running this notebook:**\n",
    "1. You need a **HuggingFace account** with access to ESM models\n",
    "2. Get your access token from: https://huggingface.co/settings/tokens\n",
    "3. Have a `sequences.csv` file ready (output from the FASTA Cleaner notebook)\n",
    "\n",
    "## How to use:\n",
    "1. **Run all cells** in order (Runtime ‚Üí Run all)\n",
    "2. **Enter your HuggingFace token** when prompted\n",
    "3. **Upload your sequences.csv** file\n",
    "4. **Configure embedding options** (layers, logits)\n",
    "5. **Click \"Generate Embeddings\"** and wait for processing\n",
    "6. **Download** the resulting embeddings file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: SETUP - Run this cell first!\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîß Setting up environment...\\n\")\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import files as colab_files\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚úÖ Running in local Jupyter environment\")\n",
    "\n",
    "# Install required packages\n",
    "print(\"\\nüì¶ Installing required packages...\")\n",
    "print(\"   This may take a few minutes on first run.\\n\")\n",
    "\n",
    "!pip install -q esm huggingface_hub ipywidgets pandas torch\n",
    "\n",
    "# Import libraries\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ipywidgets not found. Installing...\")\n",
    "    !pip install -q ipywidgets\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"‚úÖ GPU detected: {gpu_name}\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    print(\"‚ö†Ô∏è No GPU detected. Running on CPU (will be slower).\")\n",
    "\n",
    "# Model layer counts\n",
    "MODEL_LAYERS = {\"esmc_300m\": 36, \"esmc_600m\": 36}\n",
    "\n",
    "print(\"\\nüéâ Setup complete! Proceed to Step 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: HUGGINGFACE LOGIN\n",
    "# ============================================================\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Storage\n",
    "model = None\n",
    "login_status = {\"success\": False}\n",
    "\n",
    "# Create widgets\n",
    "token_input = widgets.Password(\n",
    "    placeholder=\"Paste your HuggingFace token here\",\n",
    "    description=\"HF Token:\",\n",
    "    layout=widgets.Layout(width=\"400px\")\n",
    ")\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[(\"ESMC 600M (recommended)\", \"esmc_600m\"), (\"ESMC 300M (faster)\", \"esmc_300m\")],\n",
    "    value=\"esmc_600m\",\n",
    "    description=\"Model:\",\n",
    "    layout=widgets.Layout(width=\"300px\")\n",
    ")\n",
    "\n",
    "login_btn = widgets.Button(\n",
    "    description=\"üîê Login & Load Model\",\n",
    "    button_style=\"primary\",\n",
    "    layout=widgets.Layout(width=\"200px\", height=\"40px\")\n",
    ")\n",
    "\n",
    "login_output = widgets.Output()\n",
    "\n",
    "def on_login_click(btn):\n",
    "    global model, login_status\n",
    "    with login_output:\n",
    "        clear_output()\n",
    "        token = token_input.value.strip()\n",
    "        \n",
    "        if not token:\n",
    "            print(\"‚ö†Ô∏è Please enter your HuggingFace token.\")\n",
    "            print(\"\\n   Get your token at: https://huggingface.co/settings/tokens\")\n",
    "            return\n",
    "        \n",
    "        print(\"üîÑ Logging in to HuggingFace...\")\n",
    "        try:\n",
    "            login(token=token)\n",
    "            print(\"‚úÖ Login successful!\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Login failed: {e}\")\n",
    "            print(\"\\n   Make sure your token is correct and has read access.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üîÑ Loading {model_dropdown.value} model...\")\n",
    "        print(\"   This may take 1-2 minutes on first run.\\n\")\n",
    "        \n",
    "        try:\n",
    "            from esm.models.esmc import ESMC\n",
    "            model = ESMC.from_pretrained(model_dropdown.value).to(DEVICE)\n",
    "            login_status[\"success\"] = True\n",
    "            print(f\"‚úÖ Model loaded successfully on {DEVICE.upper()}!\")\n",
    "            print(\"\\nüëá Proceed to Step 3 to upload your sequences.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load model: {e}\")\n",
    "            print(\"\\n   Make sure you have accepted the ESM model license on HuggingFace.\")\n",
    "\n",
    "login_btn.on_click(on_login_click)\n",
    "\n",
    "# Display\n",
    "display(HTML(\"<h3>üîê Step 2: Login to HuggingFace</h3>\"))\n",
    "display(HTML(\"<p>Enter your HuggingFace access token to download the ESM model:</p>\"))\n",
    "display(HTML(\"<p><small>Get your token at: <a href='https://huggingface.co/settings/tokens' target='_blank'>huggingface.co/settings/tokens</a></small></p>\"))\n",
    "display(token_input)\n",
    "display(model_dropdown)\n",
    "display(login_btn)\n",
    "display(login_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: UPLOAD SEQUENCES CSV\n",
    "# ============================================================\n",
    "\n",
    "# Storage\n",
    "sequences_df = None\n",
    "\n",
    "# Create widgets\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept=\".csv\",\n",
    "    multiple=False,\n",
    "    description=\"Upload CSV\",\n",
    "    button_style=\"primary\",\n",
    "    layout=widgets.Layout(width=\"200px\")\n",
    ")\n",
    "\n",
    "upload_output = widgets.Output()\n",
    "\n",
    "def get_file_content(data):\n",
    "    \"\"\"Extract file content as string.\"\"\"\n",
    "    if isinstance(data, bytes):\n",
    "        return data.decode(\"utf-8\")\n",
    "    elif hasattr(data, \"tobytes\"):\n",
    "        return data.tobytes().decode(\"utf-8\")\n",
    "    elif isinstance(data, str):\n",
    "        return data\n",
    "    else:\n",
    "        return str(data)\n",
    "\n",
    "def on_upload_change(change):\n",
    "    global sequences_df\n",
    "    with upload_output:\n",
    "        clear_output()\n",
    "        new_value = change[\"new\"]\n",
    "        \n",
    "        if not new_value:\n",
    "            return\n",
    "        \n",
    "        # Handle different ipywidgets versions\n",
    "        if isinstance(new_value, dict):\n",
    "            for filename, file_data in new_value.items():\n",
    "                if isinstance(file_data, dict) and \"content\" in file_data:\n",
    "                    content = get_file_content(file_data[\"content\"])\n",
    "                else:\n",
    "                    content = get_file_content(file_data)\n",
    "        elif isinstance(new_value, (list, tuple)) and len(new_value) > 0:\n",
    "            file_info = new_value[0]\n",
    "            if isinstance(file_info, dict):\n",
    "                filename = file_info.get(\"name\", \"unknown.csv\")\n",
    "                content = get_file_content(file_info.get(\"content\", b\"\"))\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Unexpected file format.\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No file detected.\")\n",
    "            return\n",
    "        \n",
    "        # Parse CSV\n",
    "        from io import StringIO\n",
    "        try:\n",
    "            sequences_df = pd.read_csv(StringIO(content), keep_default_na=False)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to parse CSV: {e}\")\n",
    "            return\n",
    "        \n",
    "        # Validate columns\n",
    "        required = {\"sequence_id\", \"sequence\"}\n",
    "        if not required.issubset(sequences_df.columns):\n",
    "            missing = required - set(sequences_df.columns)\n",
    "            print(f\"‚ùå Missing required columns: {missing}\")\n",
    "            print(\"\\n   Your CSV should have 'sequence_id' and 'sequence' columns.\")\n",
    "            print(\"   This is the format output by the FASTA Cleaner notebook.\")\n",
    "            sequences_df = None\n",
    "            return\n",
    "        \n",
    "        print(f\"‚úÖ Uploaded: {filename}\")\n",
    "        print(f\"   {len(sequences_df)} sequences found\\n\")\n",
    "        print(\"üìã Preview:\")\n",
    "        display(sequences_df.head())\n",
    "        print(\"\\nüëá Proceed to Step 4 to configure and generate embeddings.\")\n",
    "\n",
    "upload_widget.observe(on_upload_change, names=\"value\")\n",
    "\n",
    "# Display\n",
    "display(HTML(\"<h3>üì§ Step 3: Upload Your Sequences</h3>\"))\n",
    "display(HTML(\"<p>Upload the <code>sequences.csv</code> file from the FASTA Cleaner notebook:</p>\"))\n",
    "display(upload_widget)\n",
    "display(upload_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 4: GENERATE EMBEDDINGS\n",
    "# ============================================================\n",
    "\n",
    "from esm.models.esmc import LogitsConfig\n",
    "from esm.sdk.api import ESMProtein\n",
    "\n",
    "# Storage for results\n",
    "embedding_results = None\n",
    "\n",
    "# ===== OUTPUT OPTIONS =====\n",
    "embed_embeddings = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Return embeddings (last layer)\",\n",
    "    layout=widgets.Layout(width=\"250px\")\n",
    ")\n",
    "\n",
    "embed_logits = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Return logits\",\n",
    "    layout=widgets.Layout(width=\"200px\")\n",
    ")\n",
    "\n",
    "# ===== HIDDEN LAYER OPTIONS =====\n",
    "layer_mode = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"None (default)\", \"none\"),\n",
    "        (\"Last layer only\", \"last\"),\n",
    "        (\"Specific layers\", \"specific\"),\n",
    "        (\"All layers (memory intensive!)\", \"all\")\n",
    "    ],\n",
    "    value=\"none\",\n",
    "    description=\"Hidden layers:\",\n",
    "    layout=widgets.Layout(width=\"300px\")\n",
    ")\n",
    "\n",
    "layer_input = widgets.Text(\n",
    "    value=\"12, 24, 36\",\n",
    "    placeholder=\"e.g., 12, 24, 36\",\n",
    "    description=\"Layer indices:\",\n",
    "    layout=widgets.Layout(width=\"300px\"),\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "def on_layer_mode_change(change):\n",
    "    layer_input.disabled = (change[\"new\"] != \"specific\")\n",
    "\n",
    "layer_mode.observe(on_layer_mode_change, names=\"value\")\n",
    "\n",
    "# ===== PROGRESS WIDGETS =====\n",
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description=\"Progress:\",\n",
    "    bar_style=\"info\",\n",
    "    layout=widgets.Layout(width=\"400px\")\n",
    ")\n",
    "\n",
    "progress_label = widgets.Label(value=\"\")\n",
    "\n",
    "embed_btn = widgets.Button(\n",
    "    description=\"üöÄ Generate Embeddings\",\n",
    "    button_style=\"success\",\n",
    "    layout=widgets.Layout(width=\"200px\", height=\"40px\")\n",
    ")\n",
    "\n",
    "embed_output = widgets.Output()\n",
    "\n",
    "def clean_sequence(seq):\n",
    "    \"\"\"Remove non-alphabetic characters from sequence.\"\"\"\n",
    "    return re.sub(r\"[^A-Z]\", \"\", seq.upper())\n",
    "\n",
    "def parse_layer_indices(text):\n",
    "    \"\"\"Parse comma-separated layer indices.\"\"\"\n",
    "    indices = []\n",
    "    for part in text.split(\",\"):\n",
    "        part = part.strip()\n",
    "        if part.isdigit() or (part.startswith(\"-\") and part[1:].isdigit()):\n",
    "            indices.append(int(part))\n",
    "    return indices\n",
    "\n",
    "def get_layers_to_extract():\n",
    "    \"\"\"Get list of layer indices based on user selection.\"\"\"\n",
    "    mode = layer_mode.value\n",
    "    if mode == \"none\":\n",
    "        return []\n",
    "    elif mode == \"last\":\n",
    "        return [-1]\n",
    "    elif mode == \"specific\":\n",
    "        return parse_layer_indices(layer_input.value)\n",
    "    elif mode == \"all\":\n",
    "        total = MODEL_LAYERS.get(model_dropdown.value, 36)\n",
    "        return list(range(1, total + 1))\n",
    "    return []\n",
    "\n",
    "def on_embed_click(btn):\n",
    "    global embedding_results\n",
    "    \n",
    "    with embed_output:\n",
    "        clear_output()\n",
    "        \n",
    "        # Validation\n",
    "        if model is None:\n",
    "            print(\"‚ö†Ô∏è Model not loaded! Complete Step 2 first.\")\n",
    "            return\n",
    "        \n",
    "        if sequences_df is None or len(sequences_df) == 0:\n",
    "            print(\"‚ö†Ô∏è No sequences uploaded! Complete Step 3 first.\")\n",
    "            return\n",
    "        \n",
    "        # Get configuration\n",
    "        return_embeddings = embed_embeddings.value\n",
    "        return_logits = embed_logits.value\n",
    "        layers_to_extract = get_layers_to_extract()\n",
    "        \n",
    "        print(\"üîÑ Generating embeddings...\")\n",
    "        print(f\"   ‚Ä¢ Embeddings: {'Yes' if return_embeddings else 'No'}\")\n",
    "        print(f\"   ‚Ä¢ Logits: {'Yes' if return_logits else 'No'}\")\n",
    "        if layers_to_extract:\n",
    "            if len(layers_to_extract) > 5:\n",
    "                print(f\"   ‚Ä¢ Hidden layers: {len(layers_to_extract)} layers\")\n",
    "            else:\n",
    "                print(f\"   ‚Ä¢ Hidden layers: {layers_to_extract}\")\n",
    "        print()\n",
    "        \n",
    "        # Setup\n",
    "        sequence_ids = sequences_df[\"sequence_id\"].tolist()\n",
    "        sequences = sequences_df[\"sequence\"].tolist()\n",
    "        total = len(sequences)\n",
    "        \n",
    "        progress_bar.max = total\n",
    "        progress_bar.value = 0\n",
    "        \n",
    "        results = {\n",
    "            \"sequence_id\": [],\n",
    "            \"embeddings\": [],\n",
    "            \"logits\": [],\n",
    "            \"hidden_states\": [],\n",
    "            \"hidden_layers_extracted\": layers_to_extract,\n",
    "            \"model_name\": model_dropdown.value,\n",
    "            \"created_at\": datetime.now().isoformat(),\n",
    "            \"errors\": [],\n",
    "            \"config\": {\n",
    "                \"return_embeddings\": return_embeddings,\n",
    "                \"return_logits\": return_logits,\n",
    "                \"hidden_layers\": layers_to_extract if layers_to_extract else None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Process each sequence\n",
    "        for i, (seq_id, seq) in enumerate(zip(sequence_ids, sequences)):\n",
    "            progress_bar.value = i + 1\n",
    "            progress_label.value = f\"{i+1}/{total} sequences\"\n",
    "            \n",
    "            try:\n",
    "                # Clean and convert\n",
    "                cleaned = clean_sequence(seq)\n",
    "                protein = ESMProtein(\n",
    "                    sequence=cleaned,\n",
    "                    potential_sequence_of_concern=True\n",
    "                )\n",
    "                protein_tensor = model.encode(protein)\n",
    "                \n",
    "                # Main forward pass\n",
    "                main_config = LogitsConfig(\n",
    "                    sequence=return_logits,\n",
    "                    return_embeddings=return_embeddings,\n",
    "                    return_hidden_states=len(layers_to_extract) == 1,\n",
    "                    ith_hidden_layer=layers_to_extract[0] if len(layers_to_extract) == 1 else -1\n",
    "                )\n",
    "                output = model.logits(protein_tensor, main_config)\n",
    "                \n",
    "                # Build result for this sequence\n",
    "                seq_hidden = {}\n",
    "                \n",
    "                # Store results\n",
    "                results[\"sequence_id\"].append(seq_id)\n",
    "                \n",
    "                # Logits\n",
    "                if return_logits and output.logits is not None:\n",
    "                    results[\"logits\"].append(\n",
    "                        output.logits.sequence.squeeze(0).detach().cpu()\n",
    "                    )\n",
    "                else:\n",
    "                    results[\"logits\"].append(None)\n",
    "                \n",
    "                # Embeddings\n",
    "                if return_embeddings and output.embeddings is not None:\n",
    "                    results[\"embeddings\"].append(\n",
    "                        output.embeddings.squeeze(0).detach().cpu()\n",
    "                    )\n",
    "                else:\n",
    "                    results[\"embeddings\"].append(None)\n",
    "                \n",
    "                # Hidden states\n",
    "                if len(layers_to_extract) == 1:\n",
    "                    hs = getattr(output, \"hidden_states\", None)\n",
    "                    if isinstance(hs, torch.Tensor):\n",
    "                        seq_hidden[layers_to_extract[0]] = hs.squeeze().detach().cpu()\n",
    "                elif len(layers_to_extract) > 1:\n",
    "                    # Multiple layers need multiple passes\n",
    "                    for layer_idx in layers_to_extract:\n",
    "                        layer_config = LogitsConfig(\n",
    "                            sequence=False,\n",
    "                            return_embeddings=False,\n",
    "                            return_hidden_states=True,\n",
    "                            ith_hidden_layer=layer_idx\n",
    "                        )\n",
    "                        layer_output = model.logits(protein_tensor, layer_config)\n",
    "                        hs = getattr(layer_output, \"hidden_states\", None)\n",
    "                        if isinstance(hs, torch.Tensor):\n",
    "                            seq_hidden[layer_idx] = hs.squeeze().detach().cpu()\n",
    "                \n",
    "                results[\"hidden_states\"].append(seq_hidden)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                results[\"errors\"].append((seq_id, str(e)))\n",
    "                results[\"sequence_id\"].append(seq_id)\n",
    "                results[\"logits\"].append(None)\n",
    "                results[\"embeddings\"].append(None)\n",
    "                results[\"hidden_states\"].append({})\n",
    "                print(f\"‚ö†Ô∏è Error on {seq_id}: {e}\")\n",
    "        \n",
    "        embedding_results = results\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"‚úÖ EMBEDDING COMPLETE!\")\n",
    "        print(\"=\"*50)\n",
    "        print(\"\\nüìä Results:\")\n",
    "        print(f\"   ‚Ä¢ Sequences processed: {len(results['sequence_id'])}\")\n",
    "        print(f\"   ‚Ä¢ Errors: {len(results['errors'])}\")\n",
    "        \n",
    "        if results[\"embeddings\"] and results[\"embeddings\"][0] is not None:\n",
    "            print(f\"   ‚Ä¢ Embedding shape: {results['embeddings'][0].shape}\")\n",
    "        \n",
    "        if layers_to_extract:\n",
    "            print(f\"   ‚Ä¢ Hidden layers extracted: {len(layers_to_extract)}\")\n",
    "        \n",
    "        print(\"\\nüëá Proceed to Step 5 to download your embeddings.\")\n",
    "\n",
    "embed_btn.on_click(on_embed_click)\n",
    "\n",
    "# Display\n",
    "display(HTML(\"<h3>üöÄ Step 4: Generate Embeddings</h3>\"))\n",
    "display(HTML(\"<p><b>Output options:</b></p>\"))\n",
    "display(widgets.HBox([embed_embeddings, embed_logits]))\n",
    "display(HTML(\"<p><b>Hidden layer extraction:</b> (optional, for advanced analysis)</p>\"))\n",
    "display(layer_mode)\n",
    "display(layer_input)\n",
    "display(HTML(\"<br>\"))\n",
    "display(embed_btn)\n",
    "display(widgets.HBox([progress_bar, progress_label]))\n",
    "display(embed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 5: DOWNLOAD RESULTS\n",
    "# ============================================================\n",
    "\n",
    "download_output = widgets.Output()\n",
    "\n",
    "def download_embeddings(btn):\n",
    "    with download_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if embedding_results is None:\n",
    "            print(\"‚ö†Ô∏è No embeddings generated! Complete Step 4 first.\")\n",
    "            return\n",
    "        \n",
    "        filename = \"embeddings.pt\"\n",
    "        torch.save(embedding_results, filename)\n",
    "        \n",
    "        if IN_COLAB:\n",
    "            colab_files.download(filename)\n",
    "            print(f\"‚úÖ Downloading {filename}...\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Saved to: {filename}\")\n",
    "        \n",
    "        print(\"\\nüìñ To load this file later:\")\n",
    "        print(\"   import torch\")\n",
    "        print(\"   results = torch.load('embeddings.pt')\")\n",
    "        print(\"   embeddings = results['embeddings']\")\n",
    "        print(\"   sequence_ids = results['sequence_id']\")\n",
    "        print(\"\\n   # Access hidden states (if extracted):\")\n",
    "        print(\"   hidden = results['hidden_states'][0]  # First sequence\")\n",
    "        print(\"   layer_12 = hidden[12]  # Layer 12\")\n",
    "\n",
    "# Create download button\n",
    "download_btn = widgets.Button(\n",
    "    description=\"üíæ Download Embeddings\",\n",
    "    button_style=\"warning\",\n",
    "    layout=widgets.Layout(width=\"200px\", height=\"40px\")\n",
    ")\n",
    "download_btn.on_click(download_embeddings)\n",
    "\n",
    "# Display\n",
    "display(HTML(\"<h3>üíæ Step 5: Download Your Results</h3>\"))\n",
    "display(HTML(\"<p>Click the button below to download your embeddings:</p>\"))\n",
    "display(download_btn)\n",
    "display(download_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Output File Description\n",
    "\n",
    "The `embeddings.pt` file is a PyTorch file containing a dictionary with:\n",
    "\n",
    "| Key | Description |\n",
    "|-----|-------------|\n",
    "| `sequence_id` | List of sequence IDs (links to your `metadata.csv`) |\n",
    "| `embeddings` | List of last-layer embedding tensors (if enabled) |\n",
    "| `logits` | List of logits tensors (if enabled) |\n",
    "| `hidden_states` | List of dicts `{layer_idx: tensor}` for each sequence |\n",
    "| `hidden_layers_extracted` | List of layer indices that were extracted |\n",
    "| `model_name` | Name of the ESM-C model used |\n",
    "| `created_at` | Timestamp of when embeddings were generated |\n",
    "| `config` | Configuration used for this run |\n",
    "| `errors` | List of (sequence_id, error_message) for any failed sequences |\n",
    "\n",
    "### Loading the file:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Load results\n",
    "results = torch.load(\"embeddings.pt\")\n",
    "\n",
    "# Get embeddings for first sequence\n",
    "first_embedding = results[\"embeddings\"][0]  # Shape: (seq_len, embedding_dim)\n",
    "\n",
    "# Get mean embedding (useful for classification)\n",
    "mean_embedding = first_embedding.mean(dim=0)  # Shape: (embedding_dim,)\n",
    "\n",
    "# Access hidden states (if extracted)\n",
    "hidden = results[\"hidden_states\"][0]  # First sequence\n",
    "layer_12 = hidden[12]  # Get layer 12\n",
    "\n",
    "# Check which layers were extracted\n",
    "print(results[\"hidden_layers_extracted\"])  # e.g., [12, 24, 36]\n",
    "\n",
    "# Find embedding by sequence ID\n",
    "target_id = \"99603f8fb1e9\"\n",
    "idx = results[\"sequence_id\"].index(target_id)\n",
    "embedding = results[\"embeddings\"][idx]\n",
    "```\n",
    "\n",
    "> **Tip:** The `sequence_id` values match those in your `metadata.csv`, so you can easily link embeddings back to protein names, dates, and other metadata."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
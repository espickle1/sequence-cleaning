{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß¨ Protein Sequence Analysis Pipeline\n",
                "\n",
                "A complete workflow for protein sequence embedding and analysis:\n",
                "\n",
                "1. **FASTA Cleaning** - Clean sequences and parse metadata\n",
                "2. **Embedding Generation** - Generate ESM-C embeddings\n",
                "3. **Entropy Analysis** - Identify conserved and variable regions\n",
                "4. **Logits Analysis** - Analyze amino acid propensities\n",
                "5. **Export Results** - Save all outputs\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# SETUP\n",
                "# ============================================================\n",
                "\n",
                "print(\"üîß Setting up environment...\\n\")\n",
                "\n",
                "# Check environment\n",
                "try:\n",
                "    from google.colab import files as colab_files\n",
                "    IN_COLAB = True\n",
                "    print(\"‚úÖ Running in Google Colab\")\n",
                "    \n",
                "    # Install dependencies\n",
                "    !pip install -q esm huggingface_hub ipywidgets pandas torch scikit-learn matplotlib\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "    print(\"‚úÖ Running in local environment\")\n",
                "\n",
                "# Standard imports\n",
                "import sys\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "import pandas as pd\n",
                "import torch\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path.cwd()\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.insert(0, str(project_root))\n",
                "\n",
                "# Check GPU\n",
                "if torch.cuda.is_available():\n",
                "    DEVICE = \"cuda\"\n",
                "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    DEVICE = \"cpu\"\n",
                "    print(\"‚ö†Ô∏è No GPU - running on CPU\")\n",
                "\n",
                "print(\"\\nüéâ Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 1: FASTA Cleaning\n",
                "\n",
                "Clean protein sequences and parse metadata from FASTA headers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# STEP 1: FASTA CLEANING\n",
                "# ============================================================\n",
                "\n",
                "from embedding.fasta_cleaner import process_fasta_files, save_results\n",
                "import ipywidgets as widgets\n",
                "from IPython.display import display, HTML, clear_output\n",
                "\n",
                "# Storage\n",
                "sequences_df = None\n",
                "metadata_df = None\n",
                "\n",
                "# Upload widget\n",
                "fasta_upload = widgets.FileUpload(\n",
                "    accept=\".fasta,.fa,.faa,.txt\",\n",
                "    multiple=True,\n",
                "    description=\"Upload FASTA\",\n",
                "    button_style=\"primary\"\n",
                ")\n",
                "\n",
                "fasta_output = widgets.Output()\n",
                "\n",
                "def on_fasta_upload(change):\n",
                "    global sequences_df, metadata_df\n",
                "    with fasta_output:\n",
                "        clear_output()\n",
                "        if not change[\"new\"]:\n",
                "            return\n",
                "        \n",
                "        print(\"üîÑ Processing FASTA files...\")\n",
                "        \n",
                "        # Process uploaded files\n",
                "        from embedding.fasta_cleaner import process_fasta_content\n",
                "        from io import StringIO\n",
                "        \n",
                "        all_seqs = []\n",
                "        all_meta = []\n",
                "        \n",
                "        for file_info in change[\"new\"]:\n",
                "            content = file_info[\"content\"].decode(\"utf-8\")\n",
                "            seq_df, meta_df = process_fasta_content(content, file_info[\"name\"])\n",
                "            all_seqs.append(seq_df)\n",
                "            all_meta.append(meta_df)\n",
                "        \n",
                "        sequences_df = pd.concat(all_seqs, ignore_index=True)\n",
                "        metadata_df = pd.concat(all_meta, ignore_index=True)\n",
                "        \n",
                "        print(f\"‚úÖ Processed {len(sequences_df)} sequences\")\n",
                "        print(f\"\\nüìã Preview:\")\n",
                "        display(sequences_df.head())\n",
                "\n",
                "fasta_upload.observe(on_fasta_upload, names=\"value\")\n",
                "\n",
                "# Display\n",
                "display(HTML(\"<h3>üìÅ Upload FASTA Files</h3>\"))\n",
                "display(fasta_upload)\n",
                "display(fasta_output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save cleaned sequences\n",
                "if sequences_df is not None:\n",
                "    sequences_df.to_csv(\"sequences.csv\", index=False)\n",
                "    metadata_df.to_csv(\"metadata.csv\", index=False)\n",
                "    print(\"‚úÖ Saved sequences.csv and metadata.csv\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Upload FASTA files first\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 2: Embedding Generation\n",
                "\n",
                "Generate ESM-C protein embeddings using HuggingFace models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# STEP 2: EMBEDDING GENERATION\n",
                "# ============================================================\n",
                "\n",
                "from embedding.esmc_embed_lib import load_esmc_model, embed_sequences, save_embeddings\n",
                "from huggingface_hub import login\n",
                "\n",
                "# Model storage\n",
                "model = None\n",
                "embedding_results = None\n",
                "\n",
                "# Widgets\n",
                "token_input = widgets.Password(\n",
                "    placeholder=\"HuggingFace token\",\n",
                "    description=\"HF Token:\",\n",
                "    layout=widgets.Layout(width=\"400px\")\n",
                ")\n",
                "\n",
                "model_dropdown = widgets.Dropdown(\n",
                "    options=[(\"ESMC 600M\", \"esmc_600m\"), (\"ESMC 300M\", \"esmc_300m\")],\n",
                "    value=\"esmc_600m\",\n",
                "    description=\"Model:\"\n",
                ")\n",
                "\n",
                "load_btn = widgets.Button(description=\"üîê Load Model\", button_style=\"primary\")\n",
                "embed_btn = widgets.Button(description=\"üöÄ Generate Embeddings\", button_style=\"success\")\n",
                "\n",
                "progress = widgets.IntProgress(value=0, min=0, max=100, description=\"Progress:\")\n",
                "embed_output = widgets.Output()\n",
                "\n",
                "def on_load_click(btn):\n",
                "    global model\n",
                "    with embed_output:\n",
                "        clear_output()\n",
                "        print(\"üîÑ Loading model...\")\n",
                "        try:\n",
                "            model = load_esmc_model(token_input.value, model_dropdown.value)\n",
                "            print(f\"‚úÖ Model loaded on {DEVICE}\")\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå Error: {e}\")\n",
                "\n",
                "def on_embed_click(btn):\n",
                "    global embedding_results\n",
                "    with embed_output:\n",
                "        clear_output()\n",
                "        if model is None:\n",
                "            print(\"‚ö†Ô∏è Load model first\")\n",
                "            return\n",
                "        if sequences_df is None:\n",
                "            print(\"‚ö†Ô∏è Upload FASTA first\")\n",
                "            return\n",
                "        \n",
                "        print(\"üîÑ Generating embeddings...\")\n",
                "        progress.max = len(sequences_df)\n",
                "        \n",
                "        def update_progress(current, total):\n",
                "            progress.value = current\n",
                "        \n",
                "        embedding_results = embed_sequences(\n",
                "            model, sequences_df,\n",
                "            return_embeddings=True,\n",
                "            return_logits=True,\n",
                "            progress_callback=update_progress\n",
                "        )\n",
                "        \n",
                "        print(f\"‚úÖ Embedded {len(embedding_results['sequence_id'])} sequences\")\n",
                "\n",
                "load_btn.on_click(on_load_click)\n",
                "embed_btn.on_click(on_embed_click)\n",
                "\n",
                "# Display\n",
                "display(HTML(\"<h3>üîê HuggingFace Login</h3>\"))\n",
                "display(widgets.HBox([token_input, model_dropdown]))\n",
                "display(widgets.HBox([load_btn, embed_btn]))\n",
                "display(progress)\n",
                "display(embed_output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save embeddings\n",
                "if embedding_results is not None:\n",
                "    save_embeddings(embedding_results, \"embeddings.pt\")\n",
                "    print(\"‚úÖ Saved embeddings.pt\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Generate embeddings first\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 3: Entropy Analysis\n",
                "\n",
                "Calculate Shannon entropy to identify conserved and variable positions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# STEP 3: ENTROPY ANALYSIS\n",
                "# ============================================================\n",
                "\n",
                "from analysis.entropy_lib import analyze_entropy, entropy_summary\n",
                "\n",
                "# Load embeddings if needed\n",
                "if embedding_results is None:\n",
                "    if Path(\"embeddings.pt\").exists():\n",
                "        embedding_results = torch.load(\"embeddings.pt\", weights_only=False)\n",
                "        print(\"‚úÖ Loaded embeddings.pt\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Run Step 2 first or upload embeddings.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run entropy analysis\n",
                "entropy_results = None\n",
                "\n",
                "if embedding_results is not None:\n",
                "    print(\"üîÑ Calculating entropy...\")\n",
                "    \n",
                "    entropy_results = analyze_entropy(\n",
                "        embedding_results,\n",
                "        base=\"e\",\n",
                "        constrained_percentile=10.0,\n",
                "        flexible_percentile=90.0\n",
                "    )\n",
                "    \n",
                "    # Summary\n",
                "    df = entropy_summary(entropy_results)\n",
                "    print(f\"\\n‚úÖ Analyzed {len(df)} sequences\")\n",
                "    print(f\"\\nüìä Global mean entropy: {entropy_results['global_mean']:.3f}\")\n",
                "    print(f\"\\nüìã Summary:\")\n",
                "    display(df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize entropy distribution for first sequence\n",
                "if entropy_results is not None and len(entropy_results[\"entropy\"]) > 0:\n",
                "    import matplotlib.pyplot as plt\n",
                "    \n",
                "    entropy_vals = entropy_results[\"entropy\"][0].numpy()\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(12, 4))\n",
                "    ax.plot(entropy_vals, alpha=0.7)\n",
                "    ax.set_xlabel(\"Residue Position\")\n",
                "    ax.set_ylabel(\"Entropy (nats)\")\n",
                "    ax.set_title(f\"Entropy Profile: {entropy_results['sequence_id'][0]}\")\n",
                "    \n",
                "    # Mark constrained and flexible regions\n",
                "    constrained = entropy_results[\"constrained_positions\"][0].numpy()\n",
                "    flexible = entropy_results[\"flexible_positions\"][0].numpy()\n",
                "    \n",
                "    ax.scatter(constrained, entropy_vals[constrained], c=\"blue\", s=10, alpha=0.5, label=\"Constrained\")\n",
                "    ax.scatter(flexible, entropy_vals[flexible], c=\"red\", s=10, alpha=0.5, label=\"Flexible\")\n",
                "    ax.legend()\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 4: Logits Analysis\n",
                "\n",
                "Analyze amino acid propensities at specific positions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# STEP 4: LOGITS ANALYSIS\n",
                "# ============================================================\n",
                "\n",
                "from analysis.logits_lib import analyze_residues, plot_heatmap, AA_VOCAB\n",
                "\n",
                "# Define residues of interest (customize as needed)\n",
                "# Format: {position: \"label\"}\n",
                "residues_of_interest = {\n",
                "    0: \"Position 1\",\n",
                "    10: \"Position 11\",\n",
                "    20: \"Position 21\",\n",
                "    50: \"Position 51\",\n",
                "    100: \"Position 101\",\n",
                "}\n",
                "\n",
                "print(\"üìã Residues of interest:\")\n",
                "for pos, label in residues_of_interest.items():\n",
                "    print(f\"   ‚Ä¢ {pos}: {label}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze residues\n",
                "logits_analysis = None\n",
                "\n",
                "if embedding_results is not None:\n",
                "    print(\"üîÑ Analyzing logits...\")\n",
                "    \n",
                "    logits_analysis = analyze_residues(\n",
                "        embedding_results,\n",
                "        residues_of_interest=residues_of_interest,\n",
                "        pool_method=\"mean\",\n",
                "        scale_method=\"minmax\"\n",
                "    )\n",
                "    \n",
                "    print(\"‚úÖ Analysis complete\")\n",
                "    print(f\"\\nüìã Amino acid probabilities:\")\n",
                "    display(logits_analysis[\"probs\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate heatmap\n",
                "if logits_analysis is not None:\n",
                "    plot_heatmap(\n",
                "        logits_analysis[\"scaled_logits\"],\n",
                "        row_labels=logits_analysis[\"residue_labels\"],\n",
                "        col_labels=AA_VOCAB,\n",
                "        title=\"Amino Acid Propensity Heatmap\",\n",
                "        figsize=(12, 5),\n",
                "        cmap=\"coolwarm\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Step 5: Export Results\n",
                "\n",
                "Save all analysis results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# STEP 5: EXPORT RESULTS\n",
                "# ============================================================\n",
                "\n",
                "from analysis.entropy_lib import save_entropy_results\n",
                "from analysis.logits_lib import save_analysis\n",
                "\n",
                "output_dir = Path(\"results\")\n",
                "output_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# Save entropy results\n",
                "if entropy_results is not None:\n",
                "    entropy_summary(entropy_results).to_csv(output_dir / \"entropy_summary.csv\", index=False)\n",
                "    print(\"‚úÖ Saved results/entropy_summary.csv\")\n",
                "\n",
                "# Save logits analysis\n",
                "if logits_analysis is not None:\n",
                "    save_analysis(logits_analysis, str(output_dir / \"logits_analysis.csv\"))\n",
                "    print(\"‚úÖ Saved results/logits_analysis.csv\")\n",
                "\n",
                "# Save embeddings\n",
                "if embedding_results is not None:\n",
                "    save_embeddings(embedding_results, str(output_dir / \"embeddings.pt\"))\n",
                "    print(\"‚úÖ Saved results/embeddings.pt\")\n",
                "\n",
                "print(\"\\nüéâ All results saved!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download results (Colab only)\n",
                "if IN_COLAB:\n",
                "    import shutil\n",
                "    \n",
                "    # Create zip of results\n",
                "    shutil.make_archive(\"results\", \"zip\", \"results\")\n",
                "    colab_files.download(\"results.zip\")\n",
                "    print(\"üì• Downloading results.zip...\")\n",
                "else:\n",
                "    print(f\"üìÅ Results saved to: {output_dir.absolute()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìñ Pipeline Summary\n",
                "\n",
                "This notebook orchestrates the complete protein analysis workflow:\n",
                "\n",
                "| Step | Library | Input | Output |\n",
                "|------|---------|-------|--------|\n",
                "| 1. FASTA Cleaning | `embedding.fasta_cleaner` | FASTA files | `sequences.csv`, `metadata.csv` |\n",
                "| 2. Embedding | `embedding.esmc_embed_lib` | `sequences.csv` | `embeddings.pt` |\n",
                "| 3. Entropy | `analysis.entropy_lib` | `embeddings.pt` | `entropy_summary.csv` |\n",
                "| 4. Logits | `analysis.logits_lib` | `embeddings.pt` | `logits_analysis.csv`, heatmaps |\n",
                "\n",
                "### Using the libraries directly:\n",
                "\n",
                "```python\n",
                "# Import libraries\n",
                "from embedding import process_fasta_files, load_esmc_model, embed_from_csv\n",
                "from analysis import analyze_entropy, analyze_residues\n",
                "\n",
                "# Process FASTA\n",
                "seq_df, meta_df = process_fasta_files(\"proteins.fasta\")\n",
                "\n",
                "# Generate embeddings\n",
                "model = load_esmc_model(\"hf_token\")\n",
                "results = embed_from_csv(model, \"sequences.csv\")\n",
                "\n",
                "# Analyze\n",
                "entropy = analyze_entropy(results)\n",
                "logits = analyze_residues(results, residues_of_interest={100: \"D100\"})\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}